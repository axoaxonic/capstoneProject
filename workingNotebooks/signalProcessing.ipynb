{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Preprocessing\n",
    "--------------\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "This notebook is to test out preprocessing methods to see if accuracy can be increased. It should be merged with the dataPrep notebook after processing type is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pywt\n",
    "import scipy\n",
    "from scipy.signal import hilbert, savgol_filter, wavelets, periodogram\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import meegkit\n",
    "import nolds\n",
    "# import emd\n",
    "# import ica # standalone ICA package that utilizes INFOMAX, Sejnowski et al\n",
    "# from mne.preprocessing import infomax\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'event', 'device', 'channel', 'code', 'size', 'data']\n",
    "emotiv = pd.read_csv('../../fulldata/EP1.txt', delimiter='\\t', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the most correlated channel for a test column to .explode. signal processing in full timeseries format seems like a good idea\n",
    "fefF4 = emotiv[(emotiv['channel'] == 'F4')]\n",
    "fefF4['data'] = fefF4['data'].apply(lambda x: x.split(','))\n",
    "fefF4Exp = fefF4.explode('data')\n",
    "fefF4Exp['data'] =  fefF4Exp['data'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Savitzky-Golay Filter\n",
    "\n",
    "![Gif of how the filter smoothly approximates the curve at discrete time steps](https://upload.wikimedia.org/wikipedia/commons/8/89/Lissage_sg3_anim.gif)\n",
    "\n",
    "\"The idea of Savitzky-Golay filters is simple – for each sample in the filtered sequence, take its direct neighborhood of N neighbors and fit a polynomial to it. Then just evaluate the polynomial at its center (and the center of the neighborhood), point 0, and continue with the next neighborhood. \"\n",
    "\n",
    "\n",
    "-- https://bartwronski.com/2021/11/03/study-of-smoothing-filters-savitzky-golay-filters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fefF4Exp['SGFdata'] = savgol_filter(fefF4Exp['data'], 10001, 1 )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>data</th>\n",
       "      <th>SGFdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.009726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.007567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGFdata</th>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.486024</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             code      data   SGFdata\n",
       "code     1.000000  0.007567  0.009726\n",
       "data     0.007567  1.000000  0.486024\n",
       "SGFdata  0.009726  0.486024  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fefF4Exp[['code', 'data', 'SGFdata']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "5, 2 → +0.000004 increase (at least it's going in the right direction)\n",
    "\n",
    "5, 4 → 0 (higher order polynoms are too close to the noisy data)\n",
    "\n",
    "7, 1 → +0.000030 (see?)\n",
    "\n",
    "29, 1 →+0.000090\n",
    "\n",
    "101, 1→+0.000170\n",
    "\n",
    "1011,1→+0.002100\n",
    "\n",
    "10111,1→+0.002200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does the correlation stay after grouping by mean per event?\n",
    ".groupby('event').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pywt.cwt([row.split() for row in emotiv['data']], ) # this one returns array of coefs and an array of freqs \n",
    "# testCWT = scipy.signal.wavelets.cwt(dataColFlatFloat, wavelet=scipy.signal.ricker, widths=np.arange(1, 31) ) # this one just returns an NxM matrix, may lose info but could be easier to work with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICA (infomax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica.infomax1(fefF4Exp['data'])\n",
    "#\"MemoryError: Unable to allocate 2.02 PiB for an array with shape (16877097, 16877097) and data type float64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica.ica1(fefF4Exp['data'], ncomp=1, verbose=True) # any way to make this work on only a series?\n",
    "# ValueError: No axis named 1 for object type Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fefF4Exp['ICAdata'] = infomax(fefF4Exp['data'], verbose=True\n",
    "fICA = FastICA(5, whiten=True)\n",
    "\n",
    "fefF4Exp['ICAdata'] = fICA.fit_transform(fefF4Exp['data'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>ICAdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4682.051282</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4667.179487</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4662.051282</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4669.230769</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4676.410256</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>4587.692307</td>\n",
       "      <td>-0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>4592.307692</td>\n",
       "      <td>-0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>4586.153846</td>\n",
       "      <td>-0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>4589.230769</td>\n",
       "      <td>-0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>4596.410256</td>\n",
       "      <td>-0.000144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16877097 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               data   ICAdata\n",
       "11      4682.051282  0.000161\n",
       "11      4667.179487  0.000108\n",
       "11      4662.051282  0.000090\n",
       "11      4669.230769  0.000116\n",
       "11      4676.410256  0.000141\n",
       "...             ...       ...\n",
       "910473  4587.692307 -0.000175\n",
       "910473  4592.307692 -0.000158\n",
       "910473  4586.153846 -0.000180\n",
       "910473  4589.230769 -0.000169\n",
       "910473  4596.410256 -0.000144\n",
       "\n",
       "[16877097 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fefF4Exp[['data', 'ICAdata']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>data</th>\n",
       "      <th>ICAdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.011739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.011739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.007567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.004493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICAdata</th>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     event      code      size      data   ICAdata\n",
       "id       1.000000  1.000000 -0.009449 -0.006898 -0.011739 -0.011739\n",
       "event    1.000000  1.000000 -0.009449 -0.006898 -0.011739 -0.011739\n",
       "code    -0.009449 -0.009449  1.000000  0.006296  0.007567  0.007567\n",
       "size    -0.006898 -0.006898  0.006296  1.000000  0.004493  0.004493\n",
       "data    -0.011739 -0.011739  0.007567  0.004493  1.000000  1.000000\n",
       "ICAdata -0.011739 -0.011739  0.007567  0.004493  1.000000  1.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fefF4Exp.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't change the correlation at all, but would it be a helpful feature for a CNN classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Source Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isomap/other manifold reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transform\n",
    "![Gif showing a wavelet traveling along a curve over and over changing slightly in size, it's path is plotted next to it](https://upload.wikimedia.org/wikipedia/commons/9/95/Continuous_wavelet_transform.gif)\n",
    "(continuous shown here, probably going to have to use discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fefF4Exp['CWTdata'] = wavelets.cwt(fefF4Exp['data'], wavelet=scipy.signal.ricker, widths=np.arange(1, 16877097) ) \n",
    "# MemoryError: Unable to allocate 2.02 PiB for an array with shape (16877096, 16877097) and data type float64\n",
    "# lmao guess not\n",
    "\n",
    "# fefF4Exp['CWTdata'] = pywt.cwt(fefF4Exp['data'], scales=np.arange(1, 31), wavelet='bior6.8' )\n",
    "# fefF4Exp['DWTdata'] = pywt.wavedec(fefF4Exp['data'], wavelet='sym2' )\n",
    "\n",
    "# fefF4Exp['SWTdata'] = pywt.swt(fefF4Exp['data'].iloc[:-1], wavelet='bior6.8' )\n",
    "\n",
    "# keep getting errors like \n",
    "# ValueError: Length of values (3) does not match length of index (16877097)\n",
    "# but the values number changes by type of wavelet and transform.. so it's hard to tell where that's coming from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilbert Transform\n",
    "\n",
    "Wavelet transform is not ideal for neural data because it relies on windows of different sizes (see Mike X Cohen's youtube channel). Hilbert transform might be the better option\n",
    "provide unique analytic signal from real value data, so you can calculate instantaneous properties of your data\" -EstherExplains v=dy4OeAYqSqM \n",
    "\n",
    "\n",
    "HT gives amplitude and phase, so \"energy-frequency-time distribution\"\n",
    "> 1, Fourier Transform real valued signal\n",
    "> 2. Set Fourier coefficients of negative frequencies to zero so they cannot cancel out the imaginary part related to the positive frequencies during the inverse FT\n",
    "> 3. Double the amplitude related to positive frequencies for energy conservation\n",
    "> 4. Inverse Fourier transform to obtain the analytic (complex signal)\n",
    "\n",
    "\n",
    "```\n",
    "Returns xandarray Analytic signal of x, of each 1-D array along axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi        11Gi       735Mi       244Mi       2.9Gi       3.1Gi\r\n",
      "Swap:          976Mi       0.0Ki       976Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fefF4Exp['Hilbdata'] = hilbert(fefF4Exp['data']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/internals/managers.py:893: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  result[rl.indexer] = arr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>data</th>\n",
       "      <th>SGFdata</th>\n",
       "      <th>Hilbdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>-0.011739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>-0.011739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.007567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.004493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGFdata</th>\n",
       "      <td>-0.027377</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hilbdata</th>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     event      code      size      data   SGFdata  Hilbdata\n",
       "id        1.000000  1.000000 -0.009449 -0.006898 -0.011739 -0.027377 -0.011739\n",
       "event     1.000000  1.000000 -0.009449 -0.006898 -0.011739 -0.027377 -0.011739\n",
       "code     -0.009449 -0.009449  1.000000  0.006296  0.007567  0.009786  0.007567\n",
       "size     -0.006898 -0.006898  0.006296  1.000000  0.004493  0.004751  0.004493\n",
       "data     -0.011739 -0.011739  0.007567  0.004493  1.000000  0.482972  1.000000\n",
       "SGFdata  -0.027377 -0.027377  0.009786  0.004751  0.482972  1.000000  0.482972\n",
       "Hilbdata -0.011739 -0.011739  0.007567  0.004493  1.000000  0.482972  1.000000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fefF4Exp.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the Hilbert transform doesn't change the correlation at all. Maybe the Hilbert-Huang transform, which not only gives the envelope and the frequency info, but transforms it to the norm of the envelope (I think). But for this I would need a different package. The Empirical Mode Decomposition package emd seems to have it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilbert-Huang Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate = fefF4Exp['data'].diff().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/emd/support.py:225: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "imf = emd.sift.mask_sift(fefF4Exp['data'], max_imfs=3) # Intrinsic Mode Function\n",
    "IPdata, IFdata, IAdata = emd.spectra.frequency_transform(imf, sampleRate, 'nht') # Instantaneous Phase, Instantaneous Frequency, Instantaneous Amplitude\n",
    "emd.spectra.hilberthuang() # maybe above is all you need^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.61463711, 1.57079633, 0.59287713],\n",
       "       [2.93175836, 1.58118111, 0.59287713],\n",
       "       [4.0942524 , 1.63644521, 0.59287713],\n",
       "       ...,\n",
       "       [4.34524491, 0.81421972, 5.76970909],\n",
       "       [4.34524491, 0.81421972, 5.76970909],\n",
       "       [4.34524491, 0.81421972, 5.76970909]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fefF4Exp['IPdata'] = IPdata # these are 3D\n",
    "# fefF4Exp['IFdata'] = IFdata\n",
    "# fefF4Exp['IAdata'] = IAdata # don't actually need amplitude because the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Dimension & Lyapunov Exponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolds.corr_dim(fefF4Exp['data'], emb_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Spectrum Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freqdata, PSDdata = periodogram(fefF4Exp['data']) # crashes kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Freqdata), len(PSDdata)\n",
    "# Freqdata = pd.Series(Freqdata)\n",
    "# PSDdata = pd.Series(PSDdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psdInterim = pd.concat([Freqdata, PSDdata], axis=1)\n",
    "# psdInterim = psdInterim.set_axis(['Freqdata', 'PSDdata'], axis=1)\n",
    "\n",
    "# fefF4Exp = pd.concat([fefF4Exp, psdInterim], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating filtered data csv files for all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fefF3Exp = pd.read_csv('../data/fefF3Exp.csv', delimiter=',')\n",
    "fefF4Exp = pd.read_csv('../data/fefF4Exp.csv', delimiter=',')\n",
    "fefF7Exp = pd.read_csv('../data/fefF7Exp.csv', delimiter=',')\n",
    "fefF8Exp = pd.read_csv('../data/fefF8Exp.csv', delimiter=',')\n",
    "motFC5Exp = pd.read_csv('../data/motFC5Exp.csv', delimiter=',')\n",
    "motFC6Exp = pd.read_csv('../data/motFC6Exp.csv', delimiter=',')\n",
    "occ0Exp = pd.read_csv('../data/occ0Exp.csv', delimiter=',')\n",
    "occ1Exp = pd.read_csv('../data/occ1Exp.csv', delimiter=',')\n",
    "parP7Exp = pd.read_csv('../data/parP7Exp.csv', delimiter=',')\n",
    "parP8Exp = pd.read_csv('../data/parP8Exp.csv', delimiter=',')\n",
    "pfcAF3Exp = pd.read_csv('../data/pfcAF3Exp.csv', delimiter=',')\n",
    "pfcAF4Exp = pd.read_csv('../data/pfcAF4Exp.csv', delimiter=',')\n",
    "temT7Exp = pd.read_csv('../data/temT7Exp.csv', delimiter=',')\n",
    "temT8Exp = pd.read_csv('../data/temT8Exp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n",
      "/home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py:468: UserWarning: n_components is too large: it will be set to 1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fICA = FastICA(n_components=5, whiten=True)\n",
    "\n",
    "fefF3Exp['ICAdata'] = fICA.fit_transform(fefF3Exp['data'].to_numpy().reshape(-1, 1))\n",
    "fefF4Exp['ICAdata'] = fICA.fit_transform(fefF4Exp['data'].to_numpy().reshape(-1, 1))\n",
    "fefF7Exp['ICAdata'] = fICA.fit_transform(fefF7Exp['data'].to_numpy().reshape(-1, 1))\n",
    "fefF8Exp['ICAdata'] = fICA.fit_transform(fefF8Exp['data'].to_numpy().reshape(-1, 1))\n",
    "motFC5Exp['ICAdata'] = fICA.fit_transform(motFC5Exp['data'].to_numpy().reshape(-1, 1))\n",
    "motFC6Exp['ICAdata'] = fICA.fit_transform(motFC6Exp['data'].to_numpy().reshape(-1, 1))\n",
    "occ0Exp['ICAdata'] = fICA.fit_transform(occ0Exp['data'].to_numpy().reshape(-1, 1))\n",
    "occ1Exp['ICAdata'] = fICA.fit_transform(occ1Exp['data'].to_numpy().reshape(-1, 1))\n",
    "parP7Exp['ICAdata'] = fICA.fit_transform(parP7Exp['data'].to_numpy().reshape(-1, 1))\n",
    "parP8Exp['ICAdata'] = fICA.fit_transform(parP8Exp['data'].to_numpy().reshape(-1, 1))\n",
    "pfcAF3Exp['ICAdata'] = fICA.fit_transform(pfcAF3Exp['data'].to_numpy().reshape(-1, 1))\n",
    "pfcAF4Exp['ICAdata'] = fICA.fit_transform(pfcAF4Exp['data'].to_numpy().reshape(-1, 1))\n",
    "temT7Exp['ICAdata'] = fICA.fit_transform(temT7Exp['data'].to_numpy().reshape(-1, 1))\n",
    "temT8Exp['ICAdata'] = fICA.fit_transform(temT8Exp['data'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fefF3Exp['SGFdata'] = savgol_filter(fefF3Exp['data'], 10001, 1 ) \n",
    "# fefF4Exp['SGFdata'] = savgol_filter(fefF4Exp['data'], 10001, 1 ) \n",
    "# fefF7Exp['SGFdata'] = savgol_filter(fefF7Exp['data'], 10001, 1 )\n",
    "# fefF8Exp['SGFdata'] = savgol_filter(fefF8Exp['data'], 10001, 1 )\n",
    "# motFC5Exp['SGFdata'] = savgol_filter(motFC5Exp['data'], 10001, 1 )\n",
    "# motFC6Exp['SGFdata'] = savgol_filter(motFC6Exp['data'], 10001, 1 )\n",
    "# occ0Exp['SGFdata'] = savgol_filter(occ0Exp['data'], 10001, 1 )\n",
    "# occ1Exp['SGFdata'] = savgol_filter(occ1Exp['data'], 10001, 1 )\n",
    "# parP7Exp['SGFdata'] = savgol_filter(parP7Exp['data'], 10001, 1 )\n",
    "# parP8Exp['SGFdata'] = savgol_filter(parP8Exp['data'], 10001, 1 )\n",
    "# pfcAF3Exp['SGFdata'] = savgol_filter(pfcAF3Exp['data'], 10001, 1 ) \n",
    "# pfcAF4Exp['SGFdata'] = savgol_filter(pfcAF4Exp['data'], 10001, 1 )\n",
    "# temT7Exp['SGFdata'] = savgol_filter(temT7Exp['data'], 10001, 1 ) \n",
    "['SGFdata'] = savgol_filter(temT8Exp['data'], 10001, 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fefF3Exp.to_csv('../data/fefF3Proc', sep=',')\n",
    "fefF4Exp.to_csv('../data/fefF4Proc', sep=',')\n",
    "fefF7Exp.to_csv('../data/fefF7Proc', sep=',')\n",
    "fefF8Exp.to_csv('../data/fefF8Proc', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi        12Gi       177Mi       132Mi       2.4Gi       2.2Gi\r\n",
      "Swap:          976Mi       911Mi        65Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del fefF3Exp\n",
    "del fefF4Exp\n",
    "del fefF7Exp\n",
    "del fefF8Exp\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.9Gi       3.2Gi       134Mi       2.4Gi       5.2Gi\r\n",
      "Swap:          976Mi       916Mi        60Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2755"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motFC5Exp.to_csv('../data/motFC5ExpProc', sep=',')\n",
    "motFC6Exp.to_csv('../data/motFC6Proc', sep=',')\n",
    "occ0Exp.to_csv('../data/occ0ExpProc', sep=',')\n",
    "occ1Exp.to_csv('../data/occ1ExpProc', sep=',')\n",
    "\n",
    "del motFC5Exp\n",
    "del motFC6Exp\n",
    "del occ0Exp\n",
    "del occ1Exp\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.1Gi       2.2Gi       323Mi       4.2Gi       5.8Gi\r\n",
      "Swap:          976Mi       768Mi       208Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parP7Exp.to_csv('../data/parP7Proc', sep=',')\n",
    "parP8Exp.to_csv('../data/parP8Proc', sep=',')\n",
    "pfcAF3Exp.to_csv('../data/pfcAProc', sep=',')\n",
    "\n",
    "del parP7Exp\n",
    "del parP8Exp\n",
    "del pfcAF3Exp\n",
    "s\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfcAF4Exp.to_csv('../data/pfcAF4Proc', sep=',')\n",
    "temT7Exp.to_csv('../data/temT7Proc', sep=',')\n",
    "temT8Exp.to_csv('../data/temT8Proc', sep=',')\n",
    "\n",
    "del pfcAF4Exp\n",
    "del temT7Exp\n",
    "del temT8Exp\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
