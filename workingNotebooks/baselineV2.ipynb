{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE MODEL\n",
    "-----------------\n",
    "-----------------\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalMaxPooling2D, LSTM, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       6.9Gi       4.0Gi       229Mi       4.7Gi       8.1Gi\r\n",
      "Swap:          976Mi        45Mi       931Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This df will be a row-concatenated version of the same channels\n",
    "# baseline = pd.read_csv('../../baseline.csv', delimiter=',')\n",
    "# baseline.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/dfTensor.csv', delimiter=',')\n",
    "df.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>AF3</th>\n",
       "      <th>AF4</th>\n",
       "      <th>FC5</th>\n",
       "      <th>FC6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4203.076923, 4193.333333, 4194.871794, 4207.1...</td>\n",
       "      <td>[4229.743589, 4216.923076, 4207.179487, 4215.3...</td>\n",
       "      <td>[4538.461538, 4528.717948, 4524.615384, 4526.1...</td>\n",
       "      <td>[4682.051282, 4667.179487, 4662.051282, 4669.2...</td>\n",
       "      <td>[4489.230769, 4475.384615, 4474.358974, 4486.6...</td>\n",
       "      <td>[3989.23077, 3983.589744, 3987.692308, 3991.79...</td>\n",
       "      <td>[4497.948717, 4498.461538, 4494.871794, 4497.9...</td>\n",
       "      <td>[4506.666666, 4501.025641, 4496.923076, 4496.9...</td>\n",
       "      <td>[4395.384615, 4382.564102, 4377.435897, 4387.1...</td>\n",
       "      <td>[4078.461538, 4062.564102, 4055.897435, 4065.6...</td>\n",
       "      <td>[4207.692307, 4205.641025, 4200.51282, 4194.35...</td>\n",
       "      <td>[4227.692307, 4215.384615, 4210.76923, 4221.02...</td>\n",
       "      <td>[4203.076923, 4192.820512, 4194.871794, 4204.6...</td>\n",
       "      <td>[4245.641025, 4236.410256, 4218.461538, 4220.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4396.410256, 4388.717948, 4390.76923, 4395.89...</td>\n",
       "      <td>[4208.717948, 4197.435897, 4198.461538, 4203.0...</td>\n",
       "      <td>[4522.564102, 4522.051282, 4527.179487, 4521.0...</td>\n",
       "      <td>[4633.846153, 4619.487179, 4617.948717, 4618.9...</td>\n",
       "      <td>[4482.564102, 4477.435897, 4484.102564, 4484.6...</td>\n",
       "      <td>[4016.923076, 3996.410257, 3991.282052, 3996.4...</td>\n",
       "      <td>[4498.974358, 4500.0, 4499.487179, 4494.871794...</td>\n",
       "      <td>[4507.692307, 4492.307692, 4484.102564, 4492.8...</td>\n",
       "      <td>[4385.641025, 4381.538461, 4386.666666, 4383.5...</td>\n",
       "      <td>[4061.025641, 4044.615384, 4051.282051, 4060.5...</td>\n",
       "      <td>[4217.435897, 4221.538461, 4228.717948, 4224.6...</td>\n",
       "      <td>[4213.333333, 4189.743589, 4191.794871, 4211.7...</td>\n",
       "      <td>[4194.358974, 4192.307692, 4191.794871, 4188.2...</td>\n",
       "      <td>[4228.205128, 4214.871794, 4211.282051, 4213.8...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4438.974358, 4440.51282, 4445.128205, 4445.12...</td>\n",
       "      <td>[4219.487179, 4224.102564, 4230.25641, 4231.28...</td>\n",
       "      <td>[4534.871794, 4545.641025, 4552.820512, 4551.2...</td>\n",
       "      <td>[4624.615384, 4634.871794, 4646.666666, 4651.2...</td>\n",
       "      <td>[4468.717948, 4480.51282, 4493.333333, 4490.25...</td>\n",
       "      <td>[3982.564103, 3997.435898, 4006.666666, 4002.5...</td>\n",
       "      <td>[4488.717948, 4491.282051, 4492.820512, 4491.7...</td>\n",
       "      <td>[4492.820512, 4495.897435, 4506.666666, 4504.6...</td>\n",
       "      <td>[4380.51282, 4389.743589, 4395.897435, 4395.38...</td>\n",
       "      <td>[4050.76923, 4064.615384, 4079.487179, 4075.38...</td>\n",
       "      <td>[4246.666666, 4256.410256, 4262.564102, 4250.7...</td>\n",
       "      <td>[4195.897435, 4212.820512, 4226.153846, 4218.4...</td>\n",
       "      <td>[4195.384615, 4198.974358, 4202.051282, 4198.9...</td>\n",
       "      <td>[4228.205128, 4229.743589, 4245.128205, 4248.7...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4438.461538, 4427.692307, 4432.307692, 4442.5...</td>\n",
       "      <td>[4229.230769, 4222.051282, 4229.230769, 4239.4...</td>\n",
       "      <td>[4546.153846, 4538.974358, 4541.025641, 4547.1...</td>\n",
       "      <td>[4656.410256, 4647.179487, 4649.230769, 4657.9...</td>\n",
       "      <td>[4488.205128, 4475.897435, 4488.205128, 4505.6...</td>\n",
       "      <td>[4000.0, 4001.538461, 4023.589743, 4029.230769...</td>\n",
       "      <td>[4501.025641, 4495.897435, 4493.846153, 4502.5...</td>\n",
       "      <td>[4512.820512, 4507.179487, 4510.76923, 4509.74...</td>\n",
       "      <td>[4395.897435, 4390.76923, 4403.589743, 4411.28...</td>\n",
       "      <td>[4081.025641, 4077.948717, 4075.897435, 4083.0...</td>\n",
       "      <td>[4248.717948, 4243.589743, 4245.128205, 4253.8...</td>\n",
       "      <td>[4228.205128, 4210.25641, 4212.820512, 4231.28...</td>\n",
       "      <td>[4207.692307, 4203.076923, 4203.076923, 4208.2...</td>\n",
       "      <td>[4244.102564, 4234.871794, 4238.461538, 4250.7...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4452.820512, 4446.666666, 4449.743589, 4456.4...</td>\n",
       "      <td>[4233.846153, 4232.820512, 4230.25641, 4236.41...</td>\n",
       "      <td>[4551.282051, 4547.692307, 4548.717948, 4555.8...</td>\n",
       "      <td>[4669.743589, 4663.589743, 4665.641025, 4672.8...</td>\n",
       "      <td>[4454.358974, 4446.666666, 4448.205128, 4460.0...</td>\n",
       "      <td>[3997.435898, 3983.589744, 3992.820513, 4015.3...</td>\n",
       "      <td>[4487.692307, 4493.846153, 4489.230769, 4480.5...</td>\n",
       "      <td>[4504.615384, 4500.51282, 4498.974358, 4501.53...</td>\n",
       "      <td>[4395.384615, 4385.128205, 4382.051282, 4390.7...</td>\n",
       "      <td>[4074.358974, 4071.282051, 4074.358974, 4076.4...</td>\n",
       "      <td>[4251.282051, 4250.25641, 4251.282051, 4251.79...</td>\n",
       "      <td>[4208.717948, 4208.717948, 4216.923076, 4228.2...</td>\n",
       "      <td>[4207.179487, 4210.25641, 4212.307692, 4210.76...</td>\n",
       "      <td>[4247.179487, 4249.743589, 4242.051282, 4243.5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  O1  \\\n",
       "0  [4203.076923, 4193.333333, 4194.871794, 4207.1...   \n",
       "1  [4396.410256, 4388.717948, 4390.76923, 4395.89...   \n",
       "2  [4438.974358, 4440.51282, 4445.128205, 4445.12...   \n",
       "3  [4438.461538, 4427.692307, 4432.307692, 4442.5...   \n",
       "4  [4452.820512, 4446.666666, 4449.743589, 4456.4...   \n",
       "\n",
       "                                                  O2  \\\n",
       "0  [4229.743589, 4216.923076, 4207.179487, 4215.3...   \n",
       "1  [4208.717948, 4197.435897, 4198.461538, 4203.0...   \n",
       "2  [4219.487179, 4224.102564, 4230.25641, 4231.28...   \n",
       "3  [4229.230769, 4222.051282, 4229.230769, 4239.4...   \n",
       "4  [4233.846153, 4232.820512, 4230.25641, 4236.41...   \n",
       "\n",
       "                                                  F3  \\\n",
       "0  [4538.461538, 4528.717948, 4524.615384, 4526.1...   \n",
       "1  [4522.564102, 4522.051282, 4527.179487, 4521.0...   \n",
       "2  [4534.871794, 4545.641025, 4552.820512, 4551.2...   \n",
       "3  [4546.153846, 4538.974358, 4541.025641, 4547.1...   \n",
       "4  [4551.282051, 4547.692307, 4548.717948, 4555.8...   \n",
       "\n",
       "                                                  F4  \\\n",
       "0  [4682.051282, 4667.179487, 4662.051282, 4669.2...   \n",
       "1  [4633.846153, 4619.487179, 4617.948717, 4618.9...   \n",
       "2  [4624.615384, 4634.871794, 4646.666666, 4651.2...   \n",
       "3  [4656.410256, 4647.179487, 4649.230769, 4657.9...   \n",
       "4  [4669.743589, 4663.589743, 4665.641025, 4672.8...   \n",
       "\n",
       "                                                  F7  \\\n",
       "0  [4489.230769, 4475.384615, 4474.358974, 4486.6...   \n",
       "1  [4482.564102, 4477.435897, 4484.102564, 4484.6...   \n",
       "2  [4468.717948, 4480.51282, 4493.333333, 4490.25...   \n",
       "3  [4488.205128, 4475.897435, 4488.205128, 4505.6...   \n",
       "4  [4454.358974, 4446.666666, 4448.205128, 4460.0...   \n",
       "\n",
       "                                                  F8  \\\n",
       "0  [3989.23077, 3983.589744, 3987.692308, 3991.79...   \n",
       "1  [4016.923076, 3996.410257, 3991.282052, 3996.4...   \n",
       "2  [3982.564103, 3997.435898, 4006.666666, 4002.5...   \n",
       "3  [4000.0, 4001.538461, 4023.589743, 4029.230769...   \n",
       "4  [3997.435898, 3983.589744, 3992.820513, 4015.3...   \n",
       "\n",
       "                                                  T7  \\\n",
       "0  [4497.948717, 4498.461538, 4494.871794, 4497.9...   \n",
       "1  [4498.974358, 4500.0, 4499.487179, 4494.871794...   \n",
       "2  [4488.717948, 4491.282051, 4492.820512, 4491.7...   \n",
       "3  [4501.025641, 4495.897435, 4493.846153, 4502.5...   \n",
       "4  [4487.692307, 4493.846153, 4489.230769, 4480.5...   \n",
       "\n",
       "                                                  T8  \\\n",
       "0  [4506.666666, 4501.025641, 4496.923076, 4496.9...   \n",
       "1  [4507.692307, 4492.307692, 4484.102564, 4492.8...   \n",
       "2  [4492.820512, 4495.897435, 4506.666666, 4504.6...   \n",
       "3  [4512.820512, 4507.179487, 4510.76923, 4509.74...   \n",
       "4  [4504.615384, 4500.51282, 4498.974358, 4501.53...   \n",
       "\n",
       "                                                 AF3  \\\n",
       "0  [4395.384615, 4382.564102, 4377.435897, 4387.1...   \n",
       "1  [4385.641025, 4381.538461, 4386.666666, 4383.5...   \n",
       "2  [4380.51282, 4389.743589, 4395.897435, 4395.38...   \n",
       "3  [4395.897435, 4390.76923, 4403.589743, 4411.28...   \n",
       "4  [4395.384615, 4385.128205, 4382.051282, 4390.7...   \n",
       "\n",
       "                                                 AF4  \\\n",
       "0  [4078.461538, 4062.564102, 4055.897435, 4065.6...   \n",
       "1  [4061.025641, 4044.615384, 4051.282051, 4060.5...   \n",
       "2  [4050.76923, 4064.615384, 4079.487179, 4075.38...   \n",
       "3  [4081.025641, 4077.948717, 4075.897435, 4083.0...   \n",
       "4  [4074.358974, 4071.282051, 4074.358974, 4076.4...   \n",
       "\n",
       "                                                 FC5  \\\n",
       "0  [4207.692307, 4205.641025, 4200.51282, 4194.35...   \n",
       "1  [4217.435897, 4221.538461, 4228.717948, 4224.6...   \n",
       "2  [4246.666666, 4256.410256, 4262.564102, 4250.7...   \n",
       "3  [4248.717948, 4243.589743, 4245.128205, 4253.8...   \n",
       "4  [4251.282051, 4250.25641, 4251.282051, 4251.79...   \n",
       "\n",
       "                                                 FC6  \\\n",
       "0  [4227.692307, 4215.384615, 4210.76923, 4221.02...   \n",
       "1  [4213.333333, 4189.743589, 4191.794871, 4211.7...   \n",
       "2  [4195.897435, 4212.820512, 4226.153846, 4218.4...   \n",
       "3  [4228.205128, 4210.25641, 4212.820512, 4231.28...   \n",
       "4  [4208.717948, 4208.717948, 4216.923076, 4228.2...   \n",
       "\n",
       "                                                  P7  \\\n",
       "0  [4203.076923, 4192.820512, 4194.871794, 4204.6...   \n",
       "1  [4194.358974, 4192.307692, 4191.794871, 4188.2...   \n",
       "2  [4195.384615, 4198.974358, 4202.051282, 4198.9...   \n",
       "3  [4207.692307, 4203.076923, 4203.076923, 4208.2...   \n",
       "4  [4207.179487, 4210.25641, 4212.307692, 4210.76...   \n",
       "\n",
       "                                                  P8  code  \n",
       "0  [4245.641025, 4236.410256, 4218.461538, 4220.0...     6  \n",
       "1  [4228.205128, 4214.871794, 4211.282051, 4213.8...     7  \n",
       "2  [4228.205128, 4229.743589, 4245.128205, 4248.7...     9  \n",
       "3  [4244.102564, 4234.871794, 4238.461538, 4250.7...     9  \n",
       "4  [4247.179487, 4249.743589, 4242.051282, 4243.5...     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataframes for each channel, pick and choose at will\n",
    "\n",
    "# occ0 = pd.read_csv('../data/occ0Exp.csv', delimiter=',')\n",
    "# occ1 = pd.read_csv('../data/occ1Exp.csv', delimiter=',')\n",
    "# fefF3 = pd.read_csv('../data/fefF3Exp.csv', delimiter=',')\n",
    "# fefF4 = pd.read_csv('../data/fefF4Exp.csv', delimiter=',')\n",
    "# fefF7 = pd.read_csv('../data/fefF7Exp.csv', delimiter=',')\n",
    "# fefF8 = pd.read_csv('../data/fefF8Exp.csv', delimiter=',')\n",
    "# temT7 = pd.read_csv('../data/temT7Exp.csv', delimiter=',')\n",
    "# temT8 = pd.read_csv('../data/temT8Exp.csv', delimiter=',')\n",
    "# pfcAF3 = pd.read_csv('../data/pfcAF3Exp.csv', delimiter=',')\n",
    "# pfcAF4 = pd.read_csv('../data/pfcAF4Exp.csv', delimiter=',')\n",
    "# motFC5 = pd.read_csv('../data/motFC5Exp.csv', delimiter=',')\n",
    "# motFC6 = pd.read_csv('../data/motFC6Exp.csv', delimiter=',')\n",
    "# parP7 = pd.read_csv('../data/parP7Exp.csv', delimiter=',')\n",
    "# parP8 = pd.read_csv('../data/parP8Exp.csv', delimiter=',')\n",
    "\n",
    "# loading same datasets expanded with filter processing\n",
    "\n",
    "# occ0 = pd.read_csv('../data/occ0Proc.csv', delimiter=',')\n",
    "# occ1 = pd.read_csv('../data/occ1Proc.csv', delimiter=',') \n",
    "# fefF3 = pd.read_csv('../data/fefF3Proc.csv', delimiter=',')\n",
    "# fefF4 = pd.read_csv('../data/fefF4Proc.csv', delimiter=',')\n",
    "# fefF7 = pd.read_csv('../data/fefF7Proc.csv', delimiter=',')\n",
    "# fefF8 = pd.read_csv('../data/fefF8Proc.csv', delimiter=',') \n",
    "# temT7 = pd.read_csv('../data/temT7Proc.csv', delimiter=',')\n",
    "# temT8 = pd.read_csv('../data/temT8Proc.csv', delimiter=',')\n",
    "# pfcAF3 = pd.read_csv('../data/pfcAF3Proc.csv', delimiter=',')\n",
    "# pfcAF4 = pd.read_csv('../data/pfcAF4Proc.csv', delimiter=',')\n",
    "# motFC5 = pd.read_csv('../data/motFC5Proc.csv', delimiter=',')\n",
    "# motFC6 = pd.read_csv('../data/motFC6Proc.csv', delimiter=',')\n",
    "# parP7 = pd.read_csv('../data/parP7Proc.csv', delimiter=',')\n",
    "# parP8 = pd.read_csv('../data/parP8Proc.csv', delimiter=',')\n",
    "\n",
    "# occ0 = pd.read_csv('../data/occ0Wide.csv', delimiter=',')\n",
    "# occ1 = pd.read_csv('../data/occ1Wide.csv', delimiter=',') \n",
    "# fefF3 = pd.read_csv('../data/fefF3Wide.csv', delimiter=',')\n",
    "# fefF4 = pd.read_csv('../data/fefF4Wide.csv', delimiter=',')\n",
    "# fefF7 = pd.read_csv('../data/fefF7Wide.csv', delimiter=',')\n",
    "# fefF8 = pd.read_csv('../data/fefF8Wide.csv', delimiter=',') \n",
    "# temT7 = pd.read_csv('../data/temT7Wide.csv', delimiter=',')\n",
    "# temT8 = pd.read_csv('../data/temT8Wide.csv', delimiter=',')\n",
    "# pfcAF3 = pd.read_csv('../data/pfcAF3Wide.csv', delimiter=',')\n",
    "# pfcAF4 = pd.read_csv('../data/pfcAF4Wide.csv', delimiter=',')\n",
    "# motFC5 = pd.read_csv('../data/motFC5Wide.csv', delimiter=',')\n",
    "# motFC6 = pd.read_csv('../data/motFC6Wide.csv', delimiter=',')\n",
    "# parP7 = pd.read_csv('../data/parP7Wide.csv', delimiter=',')\n",
    "# parP8 = pd.read_csv('../data/parP8Wide.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del occ0\n",
    "# del occ1\n",
    "# del fefF3\n",
    "# del fefF4\n",
    "# del fefF7\n",
    "# del fefF8\n",
    "# del temT7\n",
    "# del temT8\n",
    "# del pfcAF3\n",
    "# del pfcAF4\n",
    "# del motFC5\n",
    "# del motFC6\n",
    "# del parP7\n",
    "# del parP8\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading only the dataframes from channels positively correlated with code, to save RAM\n",
    "# corrcols = [occ1, fefF4, fefF8, pfcAF4, motFC6, parP8] #removed motFC5 for being a diff shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations of averaged channels, if there is a need to pick and choose to save RAM:\n",
    "\n",
    "<sub>\n",
    "code          1.000000\n",
    "    \n",
    "&nbsp;\n",
    "    \n",
    "occ0Data     -0.000385\n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "occ1Data      0.001626\n",
    "    \n",
    "&nbsp;\n",
    "\n",
    "fefF3Data    -0.005483\n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "fefF4Data     0.008288\n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "fefF7Data    -0.004799\n",
    "\n",
    "&nbsp;\n",
    "        \n",
    "fefF8Data     0.006907\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "temT7Data    -0.002657\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "temT8Data    -0.001037\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "pfcAF3Data   -0.007512\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "pfcAF4Data    0.007591\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "motFC5Data    0.003757\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "motFC6Data    0.001372\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "parP7Data    -0.003000\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "parP8Data     0.002366\n",
    "</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       7.7Gi       946Mi       562Mi       6.9Gi       6.9Gi\r\n",
      "Swap:          976Mi        11Mi       965Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If individual columns are loaded, use this cell to process them and aggregate group them by event\n",
    "# This gets rid of the time dimension though and will make the model be highly inaccurate\n",
    "\n",
    "# dfs = [occ0, occ1, fefF3, fefF4, fefF7, fefF8, \n",
    "#        temT7, temT8, pfcAF3, pfcAF4, motFC5, motFC6, parP7, parP8]\n",
    "# for i in dfs: #dfs:\n",
    "# #     i.drop('Unnamed: 0.1', inplace=True, axis=1)\n",
    "#     i.drop(['Unnamed: 0', 'size'], inplace=True, axis=1)\n",
    "#     i['data'].astype(float, copy=False)\n",
    "#     print(i.columns)\n",
    "# #     i = i.groupby('event').mean()\n",
    "# #     print(i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non loop version of above's last line\n",
    "# occ1, fefF4, fefF8, pfcAF4, motFC5, motFC6, parP8 for corrcols\n",
    "\n",
    "# occ0 = occ0.groupby('event').mean()\n",
    "# occ1 = occ1.groupby('event').mean()\n",
    "# fefF3 = fefF3.groupby('event').mean()\n",
    "# fefF4 = fefF4.groupby('event').mean()\n",
    "# fefF7 = fefF7.groupby('event').mean()\n",
    "# fefF8 = fefF8.groupby('event').mean()\n",
    "# temT7 = temT7.groupby('event').mean()\n",
    "# temT8 = temT8.groupby('event').mean()\n",
    "# pfcAF3 = pfcAF3.groupby('event').mean()\n",
    "# pfcAF4 = pfcAF4.groupby('event').mean()\n",
    "# motFC5 = motFC5.groupby('event').mean() #this one has less rows than the rest, why?\n",
    "# motFC6 = motFC6.groupby('event').mean()\n",
    "# parP7 = parP7.groupby('event').mean()\n",
    "# parP8 = parP8.groupby('event').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Check each channel dataframe for null vals \n",
    "# for i in corrcols:\n",
    "#     print(max(i.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming data column to specify channel name in individual channel dataframes, so when they are concatenated, the full df doesn't have multiple cols with the same names\n",
    "## (use  occ1, fefF4, fefF8, pfcAF4, motFC6, parP8 for corrcols)\n",
    "\n",
    "# occ0.rename(columns={'data': 'occ0data'}, inplace=True)\n",
    "# occ1.rename(columns={'data':'occ1data', 'ICAdata':'occ1ICAdata', 'SGFdata':'occ1SGFdata'}, inplace=True)\n",
    "# fefF3.rename(columns={'data': 'fefF3data'}, inplace=True)\n",
    "# fefF4.rename(columns={'data':'fefF4data', 'ICAdata':'fefF4ICAdata', 'SGFdata':'fefF4SGFdata'}, inplace=True)\n",
    "# fefF7.rename(columns={'data': 'fefF7data'}, inplace=True)\n",
    "# fefF8.rename(columns={'data':'fefF8data', 'ICAdata':'fefF8ICAdata', 'SGFdata':'fefF8SGFdata'}, inplace=True)\n",
    "# temT7.rename(columns={'data': 'temT7data'}, inplace=True)\n",
    "# temT8.rename(columns={'data': 'temT8data'}, inplace=True)\n",
    "# pfcAF3.rename(columns={'data': 'pfcAF3data'}, inplace=True)\n",
    "# pfcAF4.rename(columns={'data':'pfcAF4data', 'ICAdata':'pfcAF4ICAdata', 'SGFdata':'pfcAF4SGFdata'}, inplace=True)\n",
    "# motFC5.rename(columns={'data': 'motFC5data'}, inplace=True)\n",
    "# motFC6.rename(columns={'data':'motFC6data', 'ICAdata':'motFC6ICAdata', 'SGFdata':'motFC6SGFdata'}, inplace=True)\n",
    "# parP7.rename(columns={'data': 'parP7data'}, inplace=True)\n",
    "# parP8.rename(columns={'data':'parP8data', 'ICAdata':'parP8ICAdata', 'SGFdata':'parP8SGFdata'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occ0.columns, occ1.columns, fefF7.columns, fefF8.columns\n",
    "# # dfs[0] #this wasn't changed with the above functions, it's only used for calling the original datasets as they were read in\n",
    "# dfsProcessed = [occ0, occ1, fefF3, fefF4, fefF7, fefF8, \n",
    "#        temT7, temT8, pfcAF3, pfcAF4, motFC5, motFC6, parP7, parP8]\n",
    "\n",
    "## Remaking this list included processed dataframes\n",
    "# corrcolsProcessed = [occ1, fefF4, fefF8, pfcAF4, motFC6, parP8] #new vars because the original list has the unprocessed dataframes in memory it seems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If using individual channel dataframes, use this cell to turn them into one df\n",
    "# full = pd.concat(corrcolsProcessed, axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full.columns.duplicated()\n",
    "# # Since the concat created duplicate code columns, using this trick to delete them:\n",
    "# #https://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns\n",
    "# #Although a different type of join might prevent the need for this\n",
    "# full = full.loc[:,~full.columns.duplicated()].copy()\n",
    "# #full = full.drop(['size', 'id' ], axis=1) # If any extraneous cols are leftover\n",
    "# full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrMatFull = full.corr()\n",
    "#corrMatFull['code']\n",
    "# check = pd.read_csv('../data/occ1Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by 0.001562 \n",
    "# del check \n",
    "\n",
    "# check = pd.read_csv('../data/fefF7Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by -0.004390.\n",
    "# del check \n",
    "\n",
    "# check = pd.read_csv('../data/occ0Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by -0.000308 \n",
    "# del check \n",
    "\n",
    "# check = pd.read_csv('../data/fefF8Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by 0.006184\n",
    "# del check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full.plot(y=['occ0Data', 'occ1Data', 'fefF7Data', 'fefF8Data'], alpha=.7 ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi        13Gi       334Mi       227Mi       1.7Gi       1.4Gi\r\n",
      "Swap:          976Mi        45Mi       931Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Baseline Model: Only O1, O2, F7, F8; No Preprocessing\n",
    "## Baseline+ : Basline+Preprocessing\n",
    "\n",
    "--------------\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up X and y, train-test split for \"full\"\n",
    "# X = full.drop('code', axis=1)\n",
    "# XExperiment = full.drop(['code', 'occ1data', 'fefF4data',\n",
    "#                          'fefF8data', 'pfcAF4data', 'motFC6data', 'parP8data',\n",
    "#                          'occ1SGFdata', 'fefF4SGFdata','fefF8SGFdata', 'pfcAF4SGFdata', #TODO change to pfc\n",
    "#                          'motFC6SGFdata', 'parP8SGFdata'], axis=1) \n",
    "# y = full['code']\n",
    "# print(X.columns, X.iloc[0], y.iloc[0], X.shape, y.shape)\n",
    "# XTrain, XTest, yTrain, yTest = train_test_split(XExperiment, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O1     [4203.076923, 4193.333333, 4194.871794, 4207.1...\n",
      "O2     [4229.743589, 4216.923076, 4207.179487, 4215.3...\n",
      "F3     [4538.461538, 4528.717948, 4524.615384, 4526.1...\n",
      "F4     [4682.051282, 4667.179487, 4662.051282, 4669.2...\n",
      "F7     [4489.230769, 4475.384615, 4474.358974, 4486.6...\n",
      "F8     [3989.23077, 3983.589744, 3987.692308, 3991.79...\n",
      "T7     [4497.948717, 4498.461538, 4494.871794, 4497.9...\n",
      "T8     [4506.666666, 4501.025641, 4496.923076, 4496.9...\n",
      "AF3    [4395.384615, 4382.564102, 4377.435897, 4387.1...\n",
      "AF4    [4078.461538, 4062.564102, 4055.897435, 4065.6...\n",
      "FC5    [4207.692307, 4205.641025, 4200.51282, 4194.35...\n",
      "FC6    [4227.692307, 4215.384615, 4210.76923, 4221.02...\n",
      "P7     [4203.076923, 4192.820512, 4194.871794, 4204.6...\n",
      "P8     [4245.641025, 4236.410256, 4218.461538, 4220.0...\n",
      "Name: 0, dtype: object <class 'numpy.int64'> (65034, 14) (65034,)\n"
     ]
    }
   ],
   "source": [
    "# Setting up X and y, train-test split for \"df\"\n",
    "X = df.drop('code', axis=1)\n",
    "y = df['code']\n",
    "print(X.iloc[0], type(y.iloc[0]), X.shape, y.shape)\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.values[0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____________________________________\r\n",
      "< brains & NN algorithms are complex! >\r\n",
      " -------------------------------------\r\n",
      "        \\   ^__^\r\n",
      "         \\  (oo)\\_______\r\n",
      "            (__)\\       )\\/\\\r\n",
      "                ||----w |\r\n",
      "                ||     ||\r\n"
     ]
    }
   ],
   "source": [
    "!cowsay brains \\& NN algorithms are complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48775, 14), (16259, 14), (48775,), (16259,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape, XTest.shape, yTrain.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = tf.reshape(XTrain, (682850, 1, XTrain.shape[1], 1))\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "# to fix error, try this: https://www.youtube.com/watch?v=k_VAKyzggJI\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "yTrainOHE = lb.fit_transform(yTrain)\n",
    "yTrainOHE = ohe.fit_transform(yTrain.to_numpy().reshape(-1,1))\n",
    "\n",
    "# ohe0 = OneHotEncoder(sparse=False)\n",
    "# yTestOHE = ohe0.fit(yTrain.to_numpy().reshape(-1,1)) # Daniel said to do this but I can't remember why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14876"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64, kernel_size=1, activation='relu', input_shape=(1,14,1)))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "# model.add(LSTM(7, input_shape=(1,14,1), activation='tanh', \n",
    "#                recurrent_activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 1, 14, 64)         128       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 1, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 14, 64)         4160      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 1, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 1, 14, 64)         4160      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 1, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 896)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                28704     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,571\n",
      "Trainable params: 38,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 682850\n  y sizes: 48775\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-f6344dc87bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrainOHE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1846\u001b[0m             )\n\u001b[1;32m   1847\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 682850\n  y sizes: 48775\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "results = model.fit(XTrain, yTrainOHE, batch_size=20,epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy for the unprocessed signal with all channels was about .1020\n",
    "\n",
    "In 6/14 channels, adding SGF data was about the same\n",
    "\n",
    "In 6/14 channels, adding SGF and dropping raw data resulted in really low accuracy and NaN loss\n",
    "\n",
    "In 6/14 channels, ICA only had a accuracy of about .1000\n",
    "\n",
    "6/14 channels, unproccessed+SGF+ICA, 22,059 params: NaN loss again, what's wrong with the data? woe be the futility of mine ways\n",
    "\n",
    "6/14 channels, SGF only, 9,771 params, accuracy still around .1000\n",
    "\n",
    "6/14 channels, raw, 9,771 params, accuracy about .1000, so the .0020 increase was only from the extra channels. Processing doesn't seem to change the accuracy at all.\n",
    "\n",
    "----------\n",
    "Using vector data rows (\"wide\"), I get this error:\n",
    "```\n",
    "UnimplementedError                        Traceback (most recent call last)\n",
    "<ipython-input-59-f6344dc87bbc> in <module>\n",
    "      1 model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "----> 2 results = model.fit(XTrain, yTrainOHE, batch_size=20,epochs=30, verbose=1)\n",
    "\n",
    "...\n",
    "\n",
    "Cast string to float is not supported\n",
    "\t [[{{node sequential_4/Cast}}]] [Op:__inference_train_function_2630]\n",
    "```\n",
    "\n",
    "but the prep function seems to work fine: column is series, col[0] is list, and col[0][0] is float\n",
    "```\n",
    "(learn-env) :~/flatiron/cap/capstoneProject/workingNotebooks$ python dataPrepV2.py \n",
    "<class 'pandas.core.series.Series'> <class 'list'> <class 'float'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-[] TODO: OHE test, validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10234331754720463"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick support vector classifier ended up getting the same accuracy, 0.10234331754720463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.51991153e-05, -1.64019496e-04,  6.11943053e-05, ...,\n",
       "         4.13683698e-05,  1.26545442e-04,  1.39856091e-05]),\n",
       " array([[2],\n",
       "        [3],\n",
       "        [0],\n",
       "        ...,\n",
       "        [8],\n",
       "        [2],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.to_numpy().reshape(-1, 1).flatten(), yTrain.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echo State Network Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 292650 into shape (48775,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-a01ff2f5544e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreadout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreservoir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48775\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# train_statesy = reservoir.run(yTrain.to_numpy().reshape(-1, 1), reset=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mreadout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 292650 into shape (48775,1)"
     ]
    }
   ],
   "source": [
    "import reservoirpy as rpy\n",
    "from reservoirpy.nodes import Reservoir, Ridge, FORCE, ESN\n",
    "\n",
    "readout = Ridge(ridge=1e-7)\n",
    "train_states = reservoir.run(XTrain.to_numpy().reshape(-1, 1), reset=True)\n",
    "# train_statesy = reservoir.run(yTrain.to_numpy().reshape(-1, 1), reset=True)\n",
    "readout = readout.fit(train_states, yTrain.to_numpy().reshape(-1, 1), warmup=10)\n",
    "test_states = reservoir.run(XTest.to_numpy().reshape(-1, 1))\n",
    "yPred = readout.run(test_states)\n",
    "\n",
    "reservoir = Reservoir(100, lr=0.5, sr=0.9)\n",
    "ridge = Ridge(ridge=1e-7)\n",
    "\n",
    "esn_model = reservoir >> ridge\n",
    "\n",
    "esn_model = esn_model.fit(XTrain.to_numpy().reshape(-1, 1), yTrain.to_numpy().reshape(-1, 1).to_numpy().reshape(-1, 1), warmup=10)\n",
    "print(reservoir.is_initialized, readout.is_initialized, readout.fitted)\n",
    "\n",
    "yPred = esn_model.run(XTest.to_numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it was nice to learn how to set one of these up, I realized after a lot of tuning the reservoirpy library doesn't seem to have good interop with pandas. Might have interesting results with 1D timestamp and 1D value arrays, but not a multidimensional dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-6: 100%|██████████| 65034/65034 [00:06<00:00, 10457.73it/s]\n",
      "Running Reservoir-6: 100%|██████████| 65034/65034 [00:06<00:00, 10306.03it/s]\n",
      "Running Model-7:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Running Model-7:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Running Model-7: 608it [00:00, 6077.69it/s]           \u001b[A\n",
      "Running Model-7: 1184it [00:00, 5977.77it/s]\u001b[A\n",
      "Running Model-7: 1774it [00:00, 5953.20it/s]\u001b[A\n",
      "Running Model-7: 2340it [00:00, 5861.04it/s]\u001b[A\n",
      "Running Model-7: 2958it [00:00, 5950.73it/s]\u001b[A\n",
      "Running Model-7: 3509it [00:00, 5809.06it/s]\u001b[A\n",
      "Running Model-7: 4114it [00:00, 5877.67it/s]\u001b[A\n",
      "Running Model-7: 4698it [00:00, 5864.64it/s]\u001b[A\n",
      "Running Model-7: 5266it [00:00, 5805.29it/s]\u001b[A\n",
      "Running Model-7: 5856it [00:01, 5832.72it/s]\u001b[A\n",
      "Running Model-7: 6438it [00:01, 5827.26it/s]\u001b[A\n",
      "Running Model-7: 7041it [00:01, 5886.27it/s]\u001b[A\n",
      "Running Model-7: 7640it [00:01, 5915.91it/s]\u001b[A\n",
      "Running Model-7: 8228it [00:01, 5904.99it/s]\u001b[A\n",
      "Running Model-7: 8820it [00:01, 5909.08it/s]\u001b[A\n",
      "Running Model-7: 9416it [00:01, 5922.98it/s]\u001b[A\n",
      "Running Model-7: 10023it [00:01, 5964.50it/s]\u001b[A\n",
      "Running Model-7: 10635it [00:01, 6009.18it/s]\u001b[A\n",
      "Running Model-7: 11236it [00:01, 5912.81it/s]\u001b[A\n",
      "Running Model-7: 11828it [00:02, 5818.73it/s]\u001b[A\n",
      "Running Model-7: 12411it [00:02, 5803.54it/s]\u001b[A\n",
      "Running Model-7: 12992it [00:02, 5790.53it/s]\u001b[A\n",
      "Running Model-7: 13572it [00:02, 5738.91it/s]\u001b[A\n",
      "Running Model-7: 14147it [00:02, 5703.06it/s]\u001b[A\n",
      "Running Model-7: 14731it [00:02, 5742.01it/s]\u001b[A\n",
      "Running Model-7: 15306it [00:02, 5728.33it/s]\u001b[A\n",
      "Running Model-7: 15890it [00:02, 5761.14it/s]\u001b[A\n",
      "Running Model-7: 16482it [00:02, 5805.01it/s]\u001b[A\n",
      "Running Model-7: 17063it [00:02, 5804.17it/s]\u001b[A\n",
      "Running Model-7: 17657it [00:03, 5843.72it/s]\u001b[A\n",
      "Running Model-7: 18258it [00:03, 5891.12it/s]\u001b[A\n",
      "Running Model-7: 18866it [00:03, 5944.25it/s]\u001b[A\n",
      "Running Model-7: 19461it [00:03, 5888.21it/s]\u001b[A\n",
      "Running Model-7: 20051it [00:03, 5788.12it/s]\u001b[A\n",
      "Running Model-7: 20644it [00:03, 5828.84it/s]\u001b[A\n",
      "Running Model-7: 21243it [00:03, 5873.62it/s]\u001b[A\n",
      "Running Model-7: 21831it [00:03, 5788.88it/s]\u001b[A\n",
      "Running Model-7: 22413it [00:03, 5795.93it/s]\u001b[A\n",
      "Running Model-7: 22999it [00:03, 5812.25it/s]\u001b[A\n",
      "Running Model-7: 23581it [00:04, 5633.60it/s]\u001b[A\n",
      "Running Model-7: 24158it [00:04, 5672.19it/s]\u001b[A\n",
      "Running Model-7: 24757it [00:04, 5762.30it/s]\u001b[A\n",
      "Running Model-7: 25335it [00:04, 5744.69it/s]\u001b[A\n",
      "Running Model-7: 25938it [00:04, 5825.64it/s]\u001b[A\n",
      "Running Model-7: 26541it [00:04, 5882.96it/s]\u001b[A\n",
      "Running Model-7: 27130it [00:04, 5822.68it/s]\u001b[A\n",
      "Running Model-7: 27713it [00:04, 5728.89it/s]\u001b[A\n",
      "Running Model-7: 28287it [00:04, 5676.58it/s]\u001b[A\n",
      "Running Model-7: 28866it [00:04, 5709.39it/s]\u001b[A\n",
      "Running Model-7: 29438it [00:05, 5634.17it/s]\u001b[A\n",
      "Running Model-7: 30002it [00:05, 5633.38it/s]\u001b[A\n",
      "Running Model-7: 30569it [00:05, 5643.93it/s]\u001b[A\n",
      "Running Model-7: 31137it [00:05, 5654.46it/s]\u001b[A\n",
      "Running Model-7: 31734it [00:05, 5743.76it/s]\u001b[A\n",
      "Running Model-7: 32327it [00:05, 5796.45it/s]\u001b[A\n",
      "Running Model-7: 32921it [00:05, 5836.26it/s]\u001b[A\n",
      "Running Model-7: 33511it [00:05, 5854.66it/s]\u001b[A\n",
      "Running Model-7: 34097it [00:05, 5827.35it/s]\u001b[A\n",
      "Running Model-7: 34680it [00:05, 5748.60it/s]\u001b[A\n",
      "Running Model-7: 35256it [00:06, 5632.46it/s]\u001b[A\n",
      "Running Model-7: 35821it [00:06, 5600.28it/s]\u001b[A\n",
      "Running Model-7: 36382it [00:06, 5593.31it/s]\u001b[A\n",
      "Running Model-7: 36969it [00:06, 5671.34it/s]\u001b[A\n",
      "Running Model-7: 37570it [00:06, 5768.24it/s]\u001b[A\n",
      "Running Model-7: 38164it [00:06, 5817.23it/s]\u001b[A\n",
      "Running Model-7: 38756it [00:06, 5845.81it/s]\u001b[A\n",
      "Running Model-7: 39342it [00:06, 5832.56it/s]\u001b[A\n",
      "Running Model-7: 39926it [00:06, 5831.38it/s]\u001b[A\n",
      "Running Model-7: 40519it [00:06, 5860.52it/s]\u001b[A\n",
      "Running Model-7: 41115it [00:07, 5887.87it/s]\u001b[A\n",
      "Running Model-7: 41711it [00:07, 5907.63it/s]\u001b[A\n",
      "Running Model-7: 42302it [00:07, 5756.75it/s]\u001b[A\n",
      "Running Model-7: 42879it [00:07, 5663.57it/s]\u001b[A\n",
      "Running Model-7: 43447it [00:07, 5589.41it/s]\u001b[A\n",
      "Running Model-7: 44007it [00:07, 5552.98it/s]\u001b[A\n",
      "Running Model-7: 44609it [00:07, 5684.41it/s]\u001b[A\n",
      "Running Model-7: 45214it [00:07, 5789.02it/s]\u001b[A\n",
      "Running Model-7: 45795it [00:07, 5662.03it/s]\u001b[A\n",
      "Running Model-7: 46363it [00:08, 5663.80it/s]\u001b[A\n",
      "Running Model-7: 46938it [00:08, 5688.58it/s]\u001b[A\n",
      "Running Model-7: 47533it [00:08, 5762.66it/s]\u001b[A\n",
      "Running Model-7: 48111it [00:08, 5678.11it/s]\u001b[A\n",
      "Running Model-7: 48680it [00:08, 5381.61it/s]\u001b[A\n",
      "Running Model-7: 49222it [00:08, 5390.64it/s]\u001b[A\n",
      "Running Model-7: 49811it [00:08, 5530.06it/s]\u001b[A\n",
      "Running Model-7: 50408it [00:08, 5654.45it/s]\u001b[A\n",
      "Running Model-7: 50979it [00:08, 5670.07it/s]\u001b[A\n",
      "Running Model-7: 51548it [00:08, 5660.56it/s]\u001b[A\n",
      "Running Model-7: 52116it [00:09, 5641.65it/s]\u001b[A\n",
      "Running Model-7: 52700it [00:09, 5694.78it/s]\u001b[A\n",
      "Running Model-7: 53271it [00:09, 5667.71it/s]\u001b[A\n",
      "Running Model-7: 53839it [00:09, 5644.05it/s]\u001b[A\n",
      "Running Model-7: 54416it [00:09, 5679.46it/s]\u001b[A\n",
      "Running Model-7: 55013it [00:09, 5760.96it/s]\u001b[A\n",
      "Running Model-7: 55619it [00:09, 5847.09it/s]\u001b[A\n",
      "Running Model-7: 56205it [00:09, 5736.22it/s]\u001b[A\n",
      "Running Model-7: 56780it [00:09, 5397.52it/s]\u001b[A\n",
      "Running Model-7: 57355it [00:09, 5496.57it/s]\u001b[A\n",
      "Running Model-7: 57940it [00:10, 5596.85it/s]\u001b[A\n",
      "Running Model-7: 58546it [00:10, 5726.75it/s]\u001b[A\n",
      "Running Model-7: 59122it [00:10, 5631.44it/s]\u001b[A\n",
      "Running Model-7: 59688it [00:10, 5584.71it/s]\u001b[A\n",
      "Running Model-7: 60274it [00:10, 5664.12it/s]\u001b[A\n",
      "Running Model-7: 60858it [00:10, 5714.58it/s]\u001b[A\n",
      "Running Model-7: 61450it [00:10, 5773.24it/s]\u001b[A\n",
      "Running Model-7: 62042it [00:10, 5813.29it/s]\u001b[A\n",
      "Running Model-7: 62625it [00:10, 5774.60it/s]\u001b[A\n",
      "Running Model-7: 63226it [00:10, 5841.09it/s]\u001b[A\n",
      "Running Model-7: 63832it [00:11, 5903.87it/s]\u001b[A\n",
      "Running Model-7: 64431it [00:11, 5928.65it/s]\u001b[A\n",
      "Running Model-7: 65034it [00:11, 5755.14it/s]\u001b[A\n",
      "Running Model-7: 100%|██████████| 1/1 [00:11<00:00, 11.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node Ridge-19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-6: 1195it [00:00, 5902.90it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model-6: 65034it [00:10, 6031.98it/s]\n"
     ]
    }
   ],
   "source": [
    "readout1 = Ridge(ridge=1e-7)\n",
    "train_states1 = reservoir.run(full['pfcAF4SGFdata'].to_numpy().reshape(-1, 1), reset=True)\n",
    "# train_statesy = reservoir.run(yTrain.to_numpy().reshape(-1, 1), reset=True)\n",
    "readout1 = readout1.fit(train_states1, full['code'].to_numpy().reshape(-1, 1), warmup=10)\n",
    "test_states1 = reservoir.run((full['pfcAF4SGFdata'].to_numpy().reshape(-1, 1)))\n",
    "# yPred1 = readout.run(test_states1)\n",
    "\n",
    "reservoir1 = Reservoir(100, lr=0.5, sr=0.9)\n",
    "ridge1 = Ridge(ridge=1e-7)\n",
    "\n",
    "esn_model1 = reservoir >> ridge\n",
    "\n",
    "esn_model1 = esn_model1.fit(full['pfcAF4SGFdata'].to_numpy().reshape(-1, 1), \n",
    "                             full['code'].to_numpy().reshape(-1, 1) ,warmup=10)\n",
    "print(reservoir.is_initialized, readout.is_initialized, readout.fitted)\n",
    "\n",
    "yPred1 = esn_model.run((full['pfcAF4SGFdata'].to_numpy().reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4.494217014863551}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(yPred1.flatten()), (mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use exploded data of one event from original CSV, predict brain activity with ESN:\n",
    "# forecast, generate artificial brainwaves of looking at a digit\n",
    "\n",
    "# TODO explore possibility of using matplotlib plots of signals as training data\n",
    "# like in https://arxiv.org/abs/1511.06448\n",
    "\n",
    "# in the future, try iterating ESNpredict -> ESNtrain -> ESNpredict -> ESNtrain -> ...\n",
    "# to see how predictions change over time, maybe there would be a \"core\" shape that can be\n",
    "# like a waveform decomposition of the number, \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
