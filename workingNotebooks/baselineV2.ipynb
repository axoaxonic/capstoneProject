{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pywt\n",
    "# import nolds\n",
    "# import scipy\n",
    "# import meegkit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # do these need to be tf.keras? review why\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalMaxPooling2D, LSTM, MaxPooling2D, Flatten \n",
    "# from sklearn.cross_decomposition import CCA \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       2.8Gi       7.0Gi       481Mi       5.7Gi        11Gi\r\n",
      "Swap:          976Mi       537Mi       439Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This df will be a row-concatenated version of the same channels\n",
    "# baseline = pd.read_csv('../../baseline.csv', delimiter=',')\n",
    "# baseline.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ0 = pd.read_csv('../data/occ0Exp.csv', delimiter=',')\n",
    "occ1 = pd.read_csv('../data/occ1Exp.csv', delimiter=',')\n",
    "fefF7 = pd.read_csv('../data/fefF7Exp.csv', delimiter=',')\n",
    "fefF8 = pd.read_csv('../data/fefF8Exp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       5.3Gi       4.5Gi       441Mi       5.7Gi       9.5Gi\r\n",
      "Swap:          976Mi       537Mi       439Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['event', 'channel', 'code', 'data'], dtype='object')\n",
      "Index(['event', 'channel', 'code', 'data'], dtype='object')\n",
      "Index(['event', 'channel', 'code', 'data'], dtype='object')\n",
      "Index(['event', 'channel', 'code', 'data'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dfs = [occ0, occ1, fefF7, fefF8]\n",
    "for i in dfs:\n",
    "    i.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "    i['data'].astype(float, copy=False)\n",
    "    print(i.columns)\n",
    "#     i = i.groupby('event').mean()\n",
    "#     print(i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in full['fefF7Code']:\n",
    "#     for j in full['fefF8Code']:\n",
    "#         print(i, j)\n",
    "        \n",
    "# it seems the event columns for each channel don't match up, cool.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non loop version of above's last line\n",
    "\n",
    "occ0 = occ1.groupby('event').mean()\n",
    "occ1 = occ1.groupby('event').mean()\n",
    "fefF7 = fefF7.groupby('event').mean()\n",
    "fefF8 = fefF8.groupby('event').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16877097\n",
      "16877097\n",
      "16877097\n",
      "16877097\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(dfs)):\n",
    "    print(len(dfs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event      0\n",
      "channel    0\n",
      "code       0\n",
      "data       0\n",
      "dtype: int64\n",
      "event      0\n",
      "channel    0\n",
      "code       0\n",
      "data       0\n",
      "dtype: int64\n",
      "event      0\n",
      "channel    0\n",
      "code       0\n",
      "data       0\n",
      "dtype: int64\n",
      "event      0\n",
      "channel    0\n",
      "code       0\n",
      "data       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in dfs:\n",
    "    print(i.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       4.8Gi       5.0Gi       444Mi       5.7Gi         9Gi\r\n",
      "Swap:          976Mi       537Mi       439Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the var names in a loop that grabs whole dfs is harder than it seems\n",
    "\n",
    "# for i in dfs:\n",
    "#     i.rename(columns={'data': f'{i}Data'}, inplace=True)\n",
    "#     i.rename(columns={'code': f'{i}Code'}, inplace=True)\n",
    "#     i.rename(columns={'event': f'{i}Event'}, inplace=True)\n",
    "#     print(i.columns)\n",
    "\n",
    "occ0.rename(columns={'data': 'occ0Data'}, inplace=True)\n",
    "occ1.rename(columns={'data': 'occ1Data'}, inplace=True)\n",
    "fefF7.rename(columns={'data': 'fefF7Data'}, inplace=True)\n",
    "fefF8.rename(columns={'data': 'fefF8Data'}, inplace=True)\n",
    "\n",
    "# occ0.rename(columns={'code': 'occ0Code'}, inplace=True)\n",
    "# occ1.rename(columns={'code': 'occ1Code'}, inplace=True)\n",
    "# fefF7.rename(columns={'code': 'fefF7Code'}, inplace=True)\n",
    "# fefF8.rename(columns={'code': 'fefF8Code'}, inplace=True)\n",
    "\n",
    "# occ0.rename(columns={'event': 'occ0Event'}, inplace=True)\n",
    "# occ1.rename(columns={'event': 'occ1Event'}, inplace=True)\n",
    "# fefF7.rename(columns={'event': 'fefF7Event'}, inplace=True)\n",
    "# fefF8.rename(columns={'event': 'fefF8Event'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[        code     occ0Data\n",
       " event                    \n",
       " 67635      6  4214.524654\n",
       " 67636      7  4221.477317\n",
       " 67637      9  4221.193910\n",
       " 67638      9  4220.273892\n",
       " 67639      0  4219.587771\n",
       " ...      ...          ...\n",
       " 132664    -1  4214.014423\n",
       " 132665    -1  4210.893429\n",
       " 132666    -1  4252.604166\n",
       " 132667    -1  4226.858974\n",
       " 132668    -1  4227.483974\n",
       " \n",
       " [65034 rows x 2 columns],\n",
       "         code     occ1Data\n",
       " event                    \n",
       " 67635      6  4214.524654\n",
       " 67636      7  4221.477317\n",
       " 67637      9  4221.193910\n",
       " 67638      9  4220.273892\n",
       " 67639      0  4219.587771\n",
       " ...      ...          ...\n",
       " 132664    -1  4214.014423\n",
       " 132665    -1  4210.893429\n",
       " 132666    -1  4252.604166\n",
       " 132667    -1  4226.858974\n",
       " 132668    -1  4227.483974\n",
       " \n",
       " [65034 rows x 2 columns],\n",
       "         code    fefF7Data\n",
       " event                    \n",
       " 67635      6  4496.575936\n",
       " 67636      7  4494.256410\n",
       " 67637      9  4461.668669\n",
       " 67638      9  4494.180264\n",
       " 67639      0  4459.374753\n",
       " ...      ...          ...\n",
       " 132664    -1  4366.262019\n",
       " 132665    -1  4444.270833\n",
       " 132666    -1  4490.667067\n",
       " 132667    -1  4499.769631\n",
       " 132668    -1  4397.572115\n",
       " \n",
       " [65034 rows x 2 columns],\n",
       "         code    fefF8Data\n",
       " event                    \n",
       " 67635      6  3988.708087\n",
       " 67636      7  4005.897436\n",
       " 67637      9  3994.072516\n",
       " 67638      9  3991.991065\n",
       " 67639      0  3991.954635\n",
       " ...      ...          ...\n",
       " 132664    -1  3997.776442\n",
       " 132665    -1  3957.584135\n",
       " 132666    -1  4032.510016\n",
       " 132667    -1  3957.451923\n",
       " 132668    -1  4001.340144\n",
       " \n",
       " [65034 rows x 2 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ0.columns, occ1.columns, fefF7.columns, fefF8.columns\n",
    "# dfs[0] #this wasn't changed with the above functions, it's only used for calling the original datasets as they were read in\n",
    "dfsProcessed = [occ0, occ1, fefF7, fefF8]\n",
    "dfsProcessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat(dfsProcessed, axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       4.8Gi       5.0Gi       459Mi       5.7Gi         9Gi\r\n",
      "Swap:          976Mi       537Mi       439Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.columns.duplicated()\n",
    "# since the concat created duplicate code columns, using this trick to delete them:\n",
    "#https://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns\n",
    "full = full.loc[:,~full.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>occ0Data</th>\n",
       "      <th>occ1Data</th>\n",
       "      <th>fefF7Data</th>\n",
       "      <th>fefF8Data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67635</th>\n",
       "      <td>6</td>\n",
       "      <td>4214.524654</td>\n",
       "      <td>4214.524654</td>\n",
       "      <td>4496.575936</td>\n",
       "      <td>3988.708087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67636</th>\n",
       "      <td>7</td>\n",
       "      <td>4221.477317</td>\n",
       "      <td>4221.477317</td>\n",
       "      <td>4494.256410</td>\n",
       "      <td>4005.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67637</th>\n",
       "      <td>9</td>\n",
       "      <td>4221.193910</td>\n",
       "      <td>4221.193910</td>\n",
       "      <td>4461.668669</td>\n",
       "      <td>3994.072516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67638</th>\n",
       "      <td>9</td>\n",
       "      <td>4220.273892</td>\n",
       "      <td>4220.273892</td>\n",
       "      <td>4494.180264</td>\n",
       "      <td>3991.991065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67639</th>\n",
       "      <td>0</td>\n",
       "      <td>4219.587771</td>\n",
       "      <td>4219.587771</td>\n",
       "      <td>4459.374753</td>\n",
       "      <td>3991.954635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code     occ0Data     occ1Data    fefF7Data    fefF8Data\n",
       "event                                                          \n",
       "67635     6  4214.524654  4214.524654  4496.575936  3988.708087\n",
       "67636     7  4221.477317  4221.477317  4494.256410  4005.897436\n",
       "67637     9  4221.193910  4221.193910  4461.668669  3994.072516\n",
       "67638     9  4220.273892  4220.273892  4494.180264  3991.991065\n",
       "67639     0  4219.587771  4219.587771  4459.374753  3991.954635"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>occ0Data</th>\n",
       "      <th>occ1Data</th>\n",
       "      <th>fefF7Data</th>\n",
       "      <th>fefF8Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>-0.004799</td>\n",
       "      <td>0.006907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occ0Data</th>\n",
       "      <td>0.001626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136258</td>\n",
       "      <td>0.135879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occ1Data</th>\n",
       "      <td>0.001626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136258</td>\n",
       "      <td>0.135879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fefF7Data</th>\n",
       "      <td>-0.004799</td>\n",
       "      <td>0.136258</td>\n",
       "      <td>0.136258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fefF8Data</th>\n",
       "      <td>0.006907</td>\n",
       "      <td>0.135879</td>\n",
       "      <td>0.135879</td>\n",
       "      <td>0.172791</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               code  occ0Data  occ1Data  fefF7Data  fefF8Data\n",
       "code       1.000000  0.001626  0.001626  -0.004799   0.006907\n",
       "occ0Data   0.001626  1.000000  1.000000   0.136258   0.135879\n",
       "occ1Data   0.001626  1.000000  1.000000   0.136258   0.135879\n",
       "fefF7Data -0.004799  0.136258  0.136258   1.000000   0.172791\n",
       "fefF8Data  0.006907  0.135879  0.135879   0.172791   1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrMatFull = full.corr()\n",
    "corrMatFull\n",
    "# check = pd.read_csv('../data/occ1Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by 0.001562 \n",
    "# del check \n",
    "\n",
    "# check = pd.read_csv('../data/fefF7Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by -0.004390.\n",
    "# del check \n",
    "\n",
    "# check = pd.read_csv('../data/occ0Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by -0.000308 \n",
    "# del check \n",
    "\n",
    "# check = pd.read_csv('../data/fefF8Exp.csv', delimiter=',')\n",
    "# print(check.corr()) # code correlates to data in this channel by 0.006184\n",
    "# del check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full.plot(y=['occ0Data', 'occ1Data', 'fefF7Data', 'fefF8Data'], alpha=.7 ); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       4.8Gi       5.0Gi       440Mi       5.7Gi         9Gi\r\n",
      "Swap:          976Mi       537Mi       439Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Baseline Model: Only O1, O2, F7, F8; No Preprocessing\n",
    "## Baseline+ : Basline+Preprocessing\n",
    "\n",
    "--------------\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['occ0Data', 'occ1Data', 'fefF7Data', 'fefF8Data'], dtype='object') 6 (65034, 4) (65034,)\n"
     ]
    }
   ],
   "source": [
    "X = full.drop('code', axis=1)\n",
    "y = full['code']\n",
    "print(X.columns, y.iloc[0], X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____________________________________\r\n",
      "< brains & NN algorithms are complex! >\r\n",
      " -------------------------------------\r\n",
      "        \\   ^__^\r\n",
      "         \\  (oo)\\_______\r\n",
      "            (__)\\       )\\/\\\r\n",
      "                ||----w |\r\n",
      "                ||     ||\r\n"
     ]
    }
   ],
   "source": [
    "!cowsay brains \\& NN algorithms are complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XTrain = XTrain.to_numpy().reshape(-1,4,1)\n",
    "XTest = XTest.to_numpy().reshape(-1,4,1)\n",
    "yTrain = yTrain.to_numpy().reshape(-1,1) # do y's need to be reshaped?\n",
    "yTest = yTest.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16259, 4, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=4, kernel_size=1, activation='relu', input_shape=(48775, 4, 1)))\n",
    "model.add(MaxPooling2D(pool_size=1))\n",
    "model.add(Conv2D(filters=4, kernel_size=1, activation='relu', input_shape=(48775, 4, 1)))\n",
    "model.add(MaxPooling2D(pool_size=1))\n",
    "model.add(Conv2D(filters=4, kernel_size=1, activation='relu', input_shape=(48775, 4, 1)))\n",
    "model.add(MaxPooling2D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# model.add(LSTM(7, input_shape=(1, 4), activation='tanh',\n",
    "#                recurrent_activation='sigmoid'))\n",
    "# model.add(LSTM(11, input_shape=(1, 4), activation='tanh',\n",
    "#                recurrent_activation='sigmoid'))\n",
    "# model.add(Dense(12, activation='softmax'))\n",
    "# model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "#getting same error training both of these models, something is wrong with the input\n",
    "# since both models produce the same error, it shouldn't be an issue of how the layers made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:191 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [None, 4, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bc0ef76ed894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adamax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'KLDivergence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/h/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:191 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [None, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adamax', loss='KLDivergence')\n",
    "model.fit(XTrain, yTrain, batch_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I'm getting the same shape error here as I got before I reshaped the training and test sets and changed from Conv1D to Conv2D, but not getting the error when I add the layers like I was, so at least I got one cell farther ^^;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Preprocessing\n",
    "--------------\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wavelet transform is not ideal for neural data because it relies on windows of different sizes (see Mike X Cohen's youtube channel). Hilbert transform might be the better option\n",
    "provide unique analytic signal from real value data, so you can calculate instantaneous properties of your data\" -EstherExplains v=dy4OeAYqSqM \n",
    "\n",
    "\n",
    "HT gives amplitude and phase, so \"energy-frequency-time distribution\"\n",
    "> 1, Fourier Transform real valued signal\n",
    "> 2. Set Fourier coefficients of negative frequencies to zero so they cannot cancel out the imaginary part related to the positive frequencies during the inverse FT\n",
    "> 3. Double the amplitude related to positive frequencies for energy conservation\n",
    "> 4. Inverse Fourier transform to obtain the analytic (complex signal)\n",
    "\n",
    "\n",
    "```\n",
    "Returns xandarray Analytic signal of x, of each 1-D array along axis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing wavelet transform and ways to parse the data column\n",
    "# pywt.cwt([row.split() for row in emotiv['data']], ) # this one returns array of coefs and an array of freqs \n",
    "# testCWT = scipy.signal.wavelets.cwt(dataColFlatFloat, wavelet=scipy.signal.ricker, widths=np.arange(1, 31) ) # this one just returns an NxM matrix, may lose info but could be easier to work with\n",
    "# type(dataColFlat[3]) # data column is all string encoded, of course, it was one giant string of numbers periods and commas\n",
    "# dataColFlatFloat = [float(i) for i in dataColFlat]\n",
    "# pd.DataFrame(testCWT).plot() #freezes comp; reduce dimensionality first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaos Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nolds.corr_dim() \n",
    "# nolds.lyap_e() # just the exponents\n",
    "# nolds.lyap_r() # oh here it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Power Spectrum Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.signal.periodogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wavelet transform is not ideal for neural data because it relies on windows of different sizes (see Mike X Cohen's youtube channel). Hilbert transform might be the better option\n",
    "provide unique analytic signal from real value data, so you can calculate instantaneous properties of your data\" -EstherExplains v=dy4OeAYqSqM \n",
    "\n",
    "\n",
    "HT gives amplitude and phase, so \"energy-frequency-time distribution\"\n",
    "> 1, Fourier Transform real valued signal\n",
    "> 2. Set Fourier coefficients of negative frequencies to zero so they cannot cancel out the imaginary part related to the positive frequencies during the inverse FT\n",
    "> 3. Double the amplitude related to positive frequencies for energy conservation\n",
    "> 4. Inverse Fourier transform to obtain the analytic (complex signal)\n",
    "\n",
    "I think the phase info is in the complex domain though. \n",
    "```\n",
    "Returns xandarray Analytic signal of x, of each 1-D array along axis\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
