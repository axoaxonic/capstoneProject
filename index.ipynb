{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT & MOTIVATION\n",
    "-----------------\n",
    "-----------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalMaxPooling2D, LSTM, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PROCESSING\n",
    "-----------------\n",
    "-----------------\n",
    "\n",
    "Uncomment and run the cell below to load and process the data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in original raw data and give it column names\n",
    "# cols = ['id', 'event', 'device', 'channel', 'code', 'size', 'data']\n",
    "# emotiv = pd.read_csv('../../fulldata/EP1.txt', delimiter='\\t', names=cols)\n",
    "# emotiv.drop(['device', 'id'], inplace=True, axis=1)\n",
    "\n",
    "# # Break up full df into sub-dfs by channel\n",
    "# occ0 = emotiv[(emotiv['channel'] == 'O1')]\n",
    "# occ1 = emotiv[(emotiv['channel'] == 'O2')]\n",
    "# fefF3 = emotiv[(emotiv['channel'] == 'F3')]\n",
    "# fefF4 = emotiv[(emotiv['channel'] == 'F4')]\n",
    "# fefF7 = emotiv[(emotiv['channel'] == 'F7')]\n",
    "# fefF8 = emotiv[(emotiv['channel'] == 'F8')]\n",
    "# temT7 = emotiv[(emotiv['channel'] == 'T7')]\n",
    "# temT8 = emotiv[(emotiv['channel'] == 'T8')]\n",
    "# pfcAF3 = emotiv[(emotiv['channel'] == 'AF3')]\n",
    "# pfcAF4 = emotiv[(emotiv['channel'] == 'AF4')]\n",
    "# motFC5 = emotiv[(emotiv['channel'] == 'FC5')]\n",
    "# motFC6 = emotiv[(emotiv['channel'] == 'FC6')]\n",
    "# parP7 = emotiv[(emotiv['channel'] == 'P7')]\n",
    "# parP8 = emotiv[(emotiv['channel'] == 'P8')]\n",
    "\n",
    "# # Delete and garbage collect the full df so computer doesn't run out of RAM and freeze\n",
    "# del emotiv\n",
    "# gc.collect()\n",
    "\n",
    "# def dataProcessor(df):\n",
    "#     '''\n",
    "# Cleans data column by splitting it into smaller strings, converting those to float, cutting it down to length defined by shortest data vector, normalizing the indexes by resetting.\n",
    "\n",
    "# i: Dataframe for single channel\n",
    "# o: Processed dataframe, printouts of lengths before and after clipping for check, timestamp for each iteration\n",
    "#     '''\n",
    "    \n",
    "#     col = df['data'].apply(lambda x: list(map(float, x.split(','))))\n",
    "#     print(type(col), type(col.iloc[0]), type(col.iloc[0][0]))\n",
    "\n",
    "#     for i in range(len(col)):\n",
    "#         l = []\n",
    "#         l.append(len(col.iloc[i]))\n",
    "\n",
    "#     print(min(l))\n",
    "\n",
    "#     for i in range(len(col)):\n",
    "#         col.iloc[i] = col.iloc[i][:256] # or 257?\n",
    "\n",
    "#     for i in range(len(col)):\n",
    "#         l = []\n",
    "#         l.append(len(col.iloc[i]))\n",
    "\n",
    "#     print(max(l))\n",
    "#     return col.reset_index(drop=True)\n",
    "\n",
    "# # Choose  which channels to include\n",
    "# dfs = [occ0, occ1, fefF3,\n",
    "#        fefF4, fefF7, fefF8, temT7,temT8,\n",
    "#         pfcAF3, pfcAF4, motFC5, motFC6,\n",
    "#         parP7, parP8]\n",
    "\n",
    "# # Init blank dataframe for processed channels to be added to\n",
    "# dfTensor = pd.DataFrame()\n",
    "\n",
    "# #  select columns by name by grabbing channel name value string from the 'channel' column\n",
    "# # then running dataProcessor on each/any channel dataframes\n",
    "# for x in dfs:\n",
    "#     name = x['channel'].iloc[0]\n",
    "#     dfTensor[name] = dataProcessor(x) \n",
    "#     print(time.time())\n",
    "\n",
    "# # Add code column from any channel df\n",
    "# dfTensor['code'] = occ1['code'].reset_index(drop=True)\n",
    "# print(dfTensor.head())\n",
    "# print(type(dfTensor), type(dfTensor.iloc[0]), type(dfTensor.iloc[0][0]))\n",
    "\n",
    "# # Delete original dfs with this ugly stack of dels, garbage collect to conserve RAM\n",
    "# del occ0\n",
    "# del occ1\n",
    "# del fefF3\n",
    "# del fefF4\n",
    "# del fefF7\n",
    "# del fefF8\n",
    "# del temT7\n",
    "# del temT8\n",
    "# del pfcAF3\n",
    "# del pfcAF4\n",
    "# del motFC5\n",
    "# del motFC6\n",
    "# del parP7\n",
    "# del parP8\n",
    "# gc.collect()\n",
    "\n",
    "# # Save resulting dataframe to csv\n",
    "# dfTensor.to_csv('../data/dfTensor.csv', sep=';', quoting=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SETUP\n",
    "-----------------\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset \n",
    "df = pd.read_csv('../data/dfTensor.csv', delimiter=';', encoding='latin-1')\n",
    "df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "#Check arbitrary column to see if the processing step encoded the data vectors as strings, which it probably did:\n",
    "df['F8'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up X and y\n",
    "X = df.drop('code', axis=1)\n",
    "y = df['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If (Since) the csv is formatted wrong, something with read_csv is encoding the lists as strings, run this to turn them back to lists\n",
    "X = X.applymap(eval) # takes a while\n",
    "print(X.iloc[0], type(y.iloc[0]), X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split for \"df\"\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape, XTest.shape, yTrain.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainNP = XTrain.applymap(np.array)\n",
    "XTrainNP = XTrainNP.to_numpy()\n",
    "XTrainNP.shape\n",
    "XTrainNP = np.reshape(XTrainNP, newshape=(256, 1, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate and setup the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=1, activation='relu', input_shape=(256,14,1)))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "# Print summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run compile and fit model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "results = model.fit(XTrain, yTrainOHE, batch_size=20,epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quck Support Vector Classification to check if there is similar performance on a simpler model\n",
    "svc = SVC()\n",
    "svc.fit(X, y)\n",
    "\n",
    "svc.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS\n",
    "---------------\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "---------------\n",
    "---------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
