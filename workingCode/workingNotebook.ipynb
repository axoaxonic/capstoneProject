{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       4.2Gi       6.6Gi       376Mi       4.8Gi        10Gi\r\n",
      "Swap:          976Mi          0B       976Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meegkit\n",
    "import time\n",
    "import pandas as pd\n",
    "# import vaex as vx\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import scipy\n",
    "#! pip3 install nolds # chaos and wavelet\n",
    "#! lesspipe ~/documents/WaveletChaosMethodologyAnalysisEEGSeizureEpilepsy.pdf\n",
    "import nolds\n",
    "import pywt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential # do these need to be tf.keras? review why\n",
    "# from tensorflow.keras.layers import Dense, Conv1D, Conv2D \n",
    "# from sklearn.cross_decomposition import CCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- [x] need maximum lyapunov method function. actually maybe just understand what max Lyap is then use \n",
    "- [x] go over keras method for cnn\n",
    "- [x] read paper, which last layer?\n",
    "- [x] idk try to load the data \n",
    "- [] and see what happens when you run some of these\n",
    "- [x] years of data cleaning and understanding\n",
    "- [] best possible way to host data for GH\n",
    "- [x] how to train test split?\n",
    "- [x] which activation function to use again? \n",
    "- [] understand dss enough to use\n",
    "- [] look up how to set optimal wavelet widths\n",
    "- [] look into which wavelet families are best for EEG\n",
    "- [x] try vaex dataframe instead of pandas\n",
    "- [x] split fef dfs\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### denoising source separation\n",
    "\n",
    "Source separation is decomposing by spatial/temporal filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meegkit.dss.dss1() # I don't understand how to use this, tutorial would be needed\n",
    "# # meegkit.dss.dss_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meegkit.cca.mcca() # avoid the orthogonal ones according to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meegkit.sns.sns() # this might be nice because dry electrodes might have high sensor noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B-Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.signal.bsplines() # I'm curious about this one too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'In mathematics and signal processing, an analytic signal is a complex-valued \n",
    "function that has no negative frequency components.[1]  The real and imaginary \n",
    "parts of an analytic signal are real-valued functions related to each other by the\n",
    "Hilbert transform.'\n",
    "\n",
    "   cool. could analyze EEG with modular forms in the upper half plane?\n",
    "    \n",
    "-----\n",
    "\n",
    "-----\n",
    "\n",
    "```\n",
    "Compute the analytic signal, using the Hilbert transform.\n",
    "The transformation is done along the last axis by default.\n",
    "Parameters xarray_like Signal data. Must be real.\n",
    "Nint, optional Number of Fourier components. Default: x.shape[axis]\n",
    "axisint, optional Axis along which to do the transformation. Default: -1.\n",
    "Returns xandarray Analytic signal of x, of each 1-D array along axis\n",
    "\n",
    "Notes\n",
    "The analytic signal x_a(t) of signal x(t) is:\n",
    "[x_a = F^{-1}(F(x) 2U) = x + i y] where F is the Fourier transform, U the unit step function, and y the Hilbert transform of x. [1]\n",
    "In other words, the negative half of the frequency spectrum is zeroed out, turning the real-valued signal into a complex signal. The Hilbert transformed signal can be obtained from np.imag(hilbert(x)), and the original signal from np.real(hilbert(x)).\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "-----\n",
    "\n",
    "> \"The Hilbert transform is the archetypical example of a singular integral operator\"\n",
    "                -https://www.sciencedirect.com/topics/mathematics/hilbert-transform\n",
    "                \n",
    "they seem to be operators that involve convolving (lol) a function along a kernal then taking the integral of that. used in harmonic analysis.\n",
    "https://en.wikipedia.org/wiki/Singular_integral\n",
    "\n",
    "\n",
    "12/12: hilbert transform doesn't really decompose the signal, but projects it through an envelope. I don't think this would help the classifier more than other types of smoothing algos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meegkit.utils.hilbert_envelope()\n",
    "# scipy.signal.hilbert() # scipy also has wavelet tools, how to choose which is best? \n",
    "# convolution of u(t) the cauchy kernel h(t) = 1/pi*t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ______________\r\n",
      "< you got this >\r\n",
      " --------------\r\n",
      "        \\   ^__^\r\n",
      "         \\  (oo)\\_______\r\n",
      "            (__)\\       )\\/\\\r\n",
      "                ||----w |\r\n",
      "                ||     ||\r\n"
     ]
    }
   ],
   "source": [
    "!cowsay you got this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding measures of chaos to the smooth feature transforms like wavelet or hilbert might give more information to the model as features, changes in fractal or chaotic dimension also relate to brain activity, although I don't know how this relates to two occipital lobe electrodes' readings off digit viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imageof the Emotiv EPOC+ headset on a white background](https://cdn-bhgin.nitrocdn.com/fYiCbyekuWxdwsIavStGyhFBtSFZmwkM/assets/static/optimized/rev-172fd76/uploads/2018/05/epoc-top-view.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "-----\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "FILE FORMAT:\n",
    "The data is stored in a very simple text format including:\n",
    "\n",
    "[id]: a numeric, only for reference purposes.\n",
    "\n",
    "[event] id, a integer, used to distinguish the same event captured at different brain locations, used only by multichannel devices (all except MW).\n",
    "\n",
    "[device]: a 2 character string, to identify the device used to capture the signals, \"MW\" for MindWave, \"EP\" for Emotive Epoc, \"MU\" for Interaxon Muse & \"IN\" for Emotiv Insight.\n",
    "\n",
    "[channel]: a string, to indentify the 10/20 brain location of the signal, with possible values:\n",
    " \n",
    "MindWave\t\"FP1\"\n",
    "EPOC\t\"AF3, \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\"\n",
    "Muse\t\"TP9,\"FP1\",\"FP2\", \"TP10\"\n",
    "Insight\t\"AF3,\"AF4\",\"T7\",\"T8\",\"PZ\" \n",
    "\n",
    "[code]: a integer, to indentify the digit been thought/seen, with possible values 0,1,2,3,4,5,6,7,8,9 or -1 for random captured signals not related to any of the digits.\n",
    "\n",
    "[size]: a integer, to identify the size in number of values captured in the 2 seconds of this signal, since the Hz of each device varies, in \"theory\" the value is close to 512Hz for MW, 128Hz for EP, 220Hz for MU & 128Hz for IN, for each of the 2 seconds.\n",
    "\n",
    "[data]: a coma separated set of numbers, with the time-series amplitude of the signal, each device uses a different precision to identify the electrical potential captured from the brain: integers in the case of MW & MU or real numbers in the case of EP & IN.\n",
    "\n",
    "There is no headers in the files,  every line is  a signal, and the fields are separated by a tab \\t\n",
    "\n",
    "For example one line of each device could be (without the headers)\n",
    "\n",
    "[id]\t[event]\t[device]\t[channel]\t[code]\t[size]\t[data]\n",
    "27\t27\tMW\tFP1\t5\t952\t18,12,13,12,5,3,11,23,37,36,26,24,35,42……\n",
    "67650\t67636\tEP\tF7\t7\t260\t4482.564102,4477.435897,4484.102564…….\n",
    "978210\t132693\tMU\tTP10\t1\t476\t506,508,509,501,497,494,497,490,490,493……\n",
    "1142043\t173652\tIN\tAF3\t0\t256\t4259.487179,4237.948717,4247.179487,4242.051282……\n",
    "```\n",
    "\n",
    "-----\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'event', 'device', 'channel', 'code', 'size', 'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       4.4Gi       6.3Gi       394Mi       4.8Gi        10Gi\r\n",
      "Swap:          976Mi          0B       976Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.12116599082947\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "emotiv = pd.read_csv('data/EP1.txt', delimiter='\\t', names=cols)\n",
    "# emotiv = vx.from_csv('data/EP1.txt', delimiter='\\t', names=cols) # you can read txts as csv, but will it parse right?\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       7.0Gi       1.0Gi       381Mi       7.5Gi       7.9Gi\r\n",
      "Swap:          976Mi          0B       976Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>device</th>\n",
       "      <th>channel</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67635</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>AF3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4395.384615,4382.564102,4377.435897,4387.17948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67636</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>F7</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4489.230769,4475.384615,4474.358974,4486.66666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67637</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>F3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4538.461538,4528.717948,4524.615384,4526.15384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67638</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>FC5</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4207.692307,4205.641025,4200.512820,4194.35897...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67639</td>\n",
       "      <td>67635</td>\n",
       "      <td>EP</td>\n",
       "      <td>T7</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4497.948717,4498.461538,4494.871794,4497.94871...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  event device channel  code  size  \\\n",
       "0  67635  67635     EP     AF3     6   260   \n",
       "1  67636  67635     EP      F7     6   260   \n",
       "2  67637  67635     EP      F3     6   260   \n",
       "3  67638  67635     EP     FC5     6   260   \n",
       "4  67639  67635     EP      T7     6   260   \n",
       "\n",
       "                                                data  \n",
       "0  4395.384615,4382.564102,4377.435897,4387.17948...  \n",
       "1  4489.230769,4475.384615,4474.358974,4486.66666...  \n",
       "2  4538.461538,4528.717948,4524.615384,4526.15384...  \n",
       "3  4207.692307,4205.641025,4200.512820,4194.35897...  \n",
       "4  4497.948717,4498.461538,4494.871794,4497.94871...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see that the device column is only EP\n",
    "len(emotiv[emotiv['device'] == 'EP'] ) == len(emotiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06686639785766602\n"
     ]
    }
   ],
   "source": [
    "# dropping device column\n",
    "t1 = time.time()\n",
    "emotiv.drop('device', inplace=True, axis=1)\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P8     65034\n",
       "P7     65034\n",
       "T7     65034\n",
       "AF4    65034\n",
       "O2     65034\n",
       "O1     65034\n",
       "F8     65034\n",
       "F3     65034\n",
       "F7     65034\n",
       "FC6    65034\n",
       "AF3    65034\n",
       "T8     65034\n",
       "F4     65034\n",
       "FC5    65034\n",
       "Name: channel, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotiv['channel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of the person who made the dataset's brain with the EEG channel locations marked on it](http://mindbigdata.com/images/DavidVivancosBrainAreas10-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Brain with locations marked, frontal eye field near the front top, up from the eyes, visual cortex in the back](https://visionhelp.files.wordpress.com/2019/07/frontal-eye-fields.jpg)\n",
    "\n",
    "FEF for gaze? IPS sends visuotopic map to FEF 10.1016/j.neuroimage.2013.05.080\n",
    "\n",
    "For more info on the frontal eye fields, check out [this Scholarpedia article](http://www.scholarpedia.org/article/Frontal_eye_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11887311935424805\n"
     ]
    }
   ],
   "source": [
    "# creating dataframes for for two regions of interest. FEF is split so notebook doesn't crash when running mapping functions to a column \n",
    "\n",
    "t1 = time.time()\n",
    "# occipital = emotiv[(emotiv['channel'] == 'O1') | (emotiv['channel'] == 'O2')]\n",
    "# occ0 = emotiv[(emotiv['channel'] == 'O1')]\n",
    "# occ1 = emotiv[(emotiv['channel'] == 'O2')]\n",
    "# fef0 = emotiv[(emotiv['channel'] == 'F3') | (emotiv['channel'] == 'F4')]\n",
    "fefF3 = emotiv[(emotiv['channel'] == 'F3')]\n",
    "fefF4 = emotiv[(emotiv['channel'] == 'F4')]\n",
    "# fef1 = emotiv[(emotiv['channel'] == 'F7')] = fefF7\n",
    "# fef2 = emotiv[(emotiv['channel'] == 'F8')] = fefF8\n",
    "# fef3 = emotiv[(emotiv['channel'] == 'FC5')] fefFC5\n",
    "# fef4 = emotiv[(emotiv['channel'] == 'FC6')] = fefFC6\n",
    "t2 = time.time()\n",
    "print(t2 - t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi        10Gi       1.3Gi       356Mi       3.7Gi       4.3Gi\r\n",
      "Swap:          976Mi       2.0Mi       974Mi\r\n"
     ]
    }
   ],
   "source": [
    "del emotiv\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the difficulty here is the data column adding another dimension. Could make another dataframe with each channel of interest as col, then data seperated into rows with .split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7868967056274414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-1ee67c7fd453>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  occipital['data'] = occipital['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "# # splitting data col into lists of readings\n",
    "# t1 = time.time()\n",
    "# occipital['data'] = occipital['data'].apply(lambda x: x.split(','))\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.385801076889038\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# occExp = occipital.explode('data') # hell yes this preserves event values for each \n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>channel</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67641</td>\n",
       "      <td>67635</td>\n",
       "      <td>O1</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4203.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67641</td>\n",
       "      <td>67635</td>\n",
       "      <td>O1</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4193.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67641</td>\n",
       "      <td>67635</td>\n",
       "      <td>O1</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4194.871794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67641</td>\n",
       "      <td>67635</td>\n",
       "      <td>O1</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4207.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67641</td>\n",
       "      <td>67635</td>\n",
       "      <td>O1</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4220.512820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910469</th>\n",
       "      <td>978104</td>\n",
       "      <td>132668</td>\n",
       "      <td>O2</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4215.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910469</th>\n",
       "      <td>978104</td>\n",
       "      <td>132668</td>\n",
       "      <td>O2</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4218.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910469</th>\n",
       "      <td>978104</td>\n",
       "      <td>132668</td>\n",
       "      <td>O2</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4212.820512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910469</th>\n",
       "      <td>978104</td>\n",
       "      <td>132668</td>\n",
       "      <td>O2</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4213.846153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910469</th>\n",
       "      <td>978104</td>\n",
       "      <td>132668</td>\n",
       "      <td>O2</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4222.564102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33754194 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   event channel  code  size         data\n",
       "6        67641   67635      O1     6   260  4203.076923\n",
       "6        67641   67635      O1     6   260  4193.333333\n",
       "6        67641   67635      O1     6   260  4194.871794\n",
       "6        67641   67635      O1     6   260  4207.179487\n",
       "6        67641   67635      O1     6   260  4220.512820\n",
       "...        ...     ...     ...   ...   ...          ...\n",
       "910469  978104  132668      O2    -1   256  4215.384615\n",
       "910469  978104  132668      O2    -1   256  4218.461538\n",
       "910469  978104  132668      O2    -1   256  4212.820512\n",
       "910469  978104  132668      O2    -1   256  4213.846153\n",
       "910469  978104  132668      O2    -1   256  4222.564102\n",
       "\n",
       "[33754194 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# occExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:        16302020     8582012     3928664      191876     3791344     7242356\r\n",
      "Swap:        1000444      608916      391528\r\n"
     ]
    }
   ],
   "source": [
    "!free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6546695232391357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-5c6b3b62ca1d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  occ0['data'] = occ0['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "# # splitting data col into lists of readings\n",
    "# t1 = time.time()\n",
    "# occ0['data'] = occ0['data'].apply(lambda x: x.split(','))\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.431585788726807\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# occ0Exp = occ0.explode('data') \n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4135041236877441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-3d23858807fb>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  occ1['data'] = occ1['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "# # splitting data col into lists of readings\n",
    "# t1 = time.time()\n",
    "# occ1['data'] = occ1['data'].apply(lambda x: x.split(','))\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.652312278747559\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# occ1Exp = occ1.explode('data') \n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1626594066619873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-5fa613fcfd24>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fefF3['data'] = fefF3['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# fefF3['data'] = fefF3['data'].apply(lambda x: x.split(','))\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.53434419631958\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# fefF3Exp = fefF3.explode('data')\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.598498821258545\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# fefF4['data'] = fefF4['data'].apply(lambda x: x.split(','))\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0803399085998535\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# fefF4Exp = fefF4.explode('data')\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2791831493377686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-27c529630f96>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fef0['data'] = fef0['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# fef0['data'] = fef0['data'].apply(lambda x: x.split(','))\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.570081233978271\n"
     ]
    }
   ],
   "source": [
    "# t1 = time.time()\n",
    "# fef0Exp = fef0.explode('data')\n",
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>channel</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67637</td>\n",
       "      <td>67635</td>\n",
       "      <td>F3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4538.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67637</td>\n",
       "      <td>67635</td>\n",
       "      <td>F3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4528.717948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67637</td>\n",
       "      <td>67635</td>\n",
       "      <td>F3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4524.615384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67637</td>\n",
       "      <td>67635</td>\n",
       "      <td>F3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4526.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67637</td>\n",
       "      <td>67635</td>\n",
       "      <td>F3</td>\n",
       "      <td>6</td>\n",
       "      <td>260</td>\n",
       "      <td>4532.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>978108</td>\n",
       "      <td>132668</td>\n",
       "      <td>F4</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4587.692307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>978108</td>\n",
       "      <td>132668</td>\n",
       "      <td>F4</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4592.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>978108</td>\n",
       "      <td>132668</td>\n",
       "      <td>F4</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4586.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>978108</td>\n",
       "      <td>132668</td>\n",
       "      <td>F4</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4589.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910473</th>\n",
       "      <td>978108</td>\n",
       "      <td>132668</td>\n",
       "      <td>F4</td>\n",
       "      <td>-1</td>\n",
       "      <td>256</td>\n",
       "      <td>4596.410256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33754194 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   event channel  code  size         data\n",
       "2        67637   67635      F3     6   260  4538.461538\n",
       "2        67637   67635      F3     6   260  4528.717948\n",
       "2        67637   67635      F3     6   260  4524.615384\n",
       "2        67637   67635      F3     6   260  4526.153846\n",
       "2        67637   67635      F3     6   260  4532.307692\n",
       "...        ...     ...     ...   ...   ...          ...\n",
       "910473  978108  132668      F4    -1   256  4587.692307\n",
       "910473  978108  132668      F4    -1   256  4592.307692\n",
       "910473  978108  132668      F4    -1   256  4586.153846\n",
       "910473  978108  132668      F4    -1   256  4589.230769\n",
       "910473  978108  132668      F4    -1   256  4596.410256\n",
       "\n",
       "[33754194 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fef0Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(fef0Exp) == len(occExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:        16302020    12888728     2674452      150632      738840     2978440\r\n",
      "Swap:        1000444      633928      366516\r\n"
     ]
    }
   ],
   "source": [
    "# !free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each exploded dataframe of 2 channels takes up 4306716 bytes of RAM. fef1 thru fef4 would be approximately half that, 2153358, but RAM is already almost maxed out \n"
     ]
    }
   ],
   "source": [
    "# print(f'each exploded dataframe of 2 channels takes up {12888728 - 8582012} bytes of RAM. fef1 thru fef4 would be approximately half that, {int((12888728 - 8582012)/2)}, but RAM is already almost maxed out ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5413436889648438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-026a8fe02f5b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fef1['data'] = fef1['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef1['data'] = fef1['data'].apply(lambda x: x.split(','))\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       5.2Gi       4.3Gi       165Mi       6.0Gi       9.9Gi\r\n",
      "Swap:          976Mi       572Mi       404Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.969892978668213\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef1Exp = fef1.explode('data')\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       6.1Gi       3.4Gi       166Mi       6.0Gi       9.0Gi\r\n",
      "Swap:          976Mi       572Mi       404Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9491031169891357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-42e665f9ef99>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fef2['data'] = fef2['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef2['data'] = fef2['data'].apply(lambda x: x.split(','))\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       6.1Gi       3.4Gi       169Mi       6.0Gi       8.9Gi\r\n",
      "Swap:          976Mi       572Mi       404Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13271117210388184\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef2Exp = fef2.explode('data')\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       6.1Gi       3.4Gi       165Mi       6.0Gi       8.9Gi\r\n",
      "Swap:          976Mi       572Mi       404Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv's to file, maybe loading them into another notebook without having to load the\n",
    "# whole dataset will make it work\n",
    "\n",
    "# occExp.to_csv('occExp.csv')\n",
    "# occ0Exp.to_csv('occ0Exp.csv')\n",
    "# occ1Exp.to_csv('occ1Exp.csv')\n",
    "# fef0Exp.to_csv('fef0Exp.csv')\n",
    "# fef1Exp.to_csv('fef1Exp.csv')\n",
    "# fef2Exp.to_csv('fef2Exp.csv')\n",
    "# fef3Exp.to_csv('fef3Exp.csv')\n",
    "# fef4Exp.to_csv('fef4Exp.csv')\n",
    "# fefF3Exp.to_csv('fefF3Exp.csv')\n",
    "# fefF4Exp.to_csv('fefF4Exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del occ0 # how to actually clear from memory? this just forgets the var alias\n",
    "del occ0Exp\n",
    "del occ1\n",
    "del occ1Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi        10Gi       1.3Gi       357Mi       3.7Gi       4.4Gi\r\n",
      "Swap:          976Mi       2.0Mi       974Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7492790222167969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-b5abad04262b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fef3['data'] = fef3['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef3['data'] = fef3['data'].apply(lambda x: x.split(','))\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       7.3Gi       1.3Gi       183Mi       6.9Gi       7.8Gi\r\n",
      "Swap:          976Mi       571Mi       405Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.24941873550415\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef3Exp = fef3.explode('data')\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       8.2Gi       1.2Gi       157Mi       6.2Gi       6.9Gi\r\n",
      "Swap:          976Mi       571Mi       405Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.185546636581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-18f58c24b744>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fef4['data'] = fef4['data'].apply(lambda x: x.split(','))\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef4['data'] = fef4['data'].apply(lambda x: x.split(','))\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi       9.3Gi       181Mi       161Mi       6.0Gi       5.8Gi\r\n",
      "Swap:          976Mi       571Mi       405Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.818826198577881\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "fef4Exp = fef4.explode('data')\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15Gi        10Gi       1.2Gi       158Mi       4.1Gi       4.9Gi\r\n",
      "Swap:          976Mi       571Mi       405Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wavelet transform is not ideal for neural data because it relies on windows of different sizes (see Mike X Cohen's youtube channel). Hilbert transform might be the better option\n",
    "provide unique analytic signal from real value data, so you can calculate instantaneous properties of your data\" -EstherExplains v=dy4OeAYqSqM \n",
    "\n",
    "\n",
    "HT gives amplitude and phase, so \"energy-frequency-time distribution\"\n",
    "> 1, Fourier Transform real valued signal\n",
    "> 2. Set Fourier coefficients of negative frequencies to zero so they cannot cancel out the imaginary part related to the positive frequencies during the inverse FT\n",
    "> 3. Double the amplitude related to positive frequencies for energy conservation\n",
    "> 4. Inverse Fourier transform to obtain the analytic (complex signal)\n",
    "\n",
    "I think the phase info is in the complex domain though. \n",
    "```\n",
    "Returns xandarray Analytic signal of x, of each 1-D array along axis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing wavelet transform and ways to parse the data column\n",
    "# pywt.cwt([row.split() for row in emotiv['data']], ) # this one returns array of coefs and an array of freqs \n",
    "# testCWT = scipy.signal.wavelets.cwt(dataColFlatFloat, wavelet=scipy.signal.ricker, widths=np.arange(1, 31) ) # this one just returns an NxM matrix, may lose info but could be easier to work with\n",
    "# type(dataColFlat[3]) # data column is all string encoded, of course, it was one giant string of numbers periods and commas\n",
    "# dataColFlatFloat = [float(i) for i in dataColFlat]\n",
    "# pd.DataFrame(testCWT).plot() #freezes comp; reduce dimensionality first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nolds.corr_dim() \n",
    "# nolds.lyap_e() # just the exponents\n",
    "# nolds.lyap_r() # oh here it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('IN.txt') as f:\n",
    "#     full = f.read()\n",
    "# full[0:30000] # aahhh\n",
    "# len(set(full)) # way more maneageable. there are 14 channels, 21 unique values\n",
    "# len(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full.find('O1') # is it not there?\n",
    "# # full[-1]  # I think this is the mindwave one oops \n",
    "# with open('./EP1.01.txt') as g:\n",
    "#     epoc = g.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # epoc.find('O1') # yay it's there 18881\n",
    "# # epoc.find('O2') # yay it's there 22025\n",
    "# epoc.split()[:4000] # what's the best way to parse this into a df? loop like fizzbuzz? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Power Spectrum Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.signal.periodogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## model skeleton\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "model.add(Conv1D(n, activation='relu'), input_dim=m, ) # or selu\n",
    "model.add(Conv1D(n, activation='relu'), input_dim=m, )\n",
    "model.add(Conv1D(n, activation='relu'), input_dim=m, )\n",
    "model.add(Dense(n, activation='softmax'), input_dim=m, )\n",
    "model.add(Dense(n, activation='softmax'), input_dim=m, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## References\n",
    "---------------\n",
    "\n",
    "https://doi.org/10.3389/fnhum.2018.00390 \"Frontal Eye Field Involvement in Color and Motion Feature-Based Attention: Single-Pulse Transcranial Magnetic Stimulation\", Xi Chen, Jing-Na Jin, Fang Xiang, Zhi-Peng Liu and Tao Yin, Front. Hum. Neurosci., 01 October 2018\n",
    "Sec. Brain Imaging and Stimulation \n",
    "\n",
    "https://doi.org/10.1016/j.neuroimage.2013.05.080\n",
    "\"Structural connectivity of visuotopic intraparietal sulcus\", SigneBrayabcdAiden E.G.F.ArnoldceGiuseppeIariacdefGlendaMacQueenbc\n",
    "\n",
    "http://www.scholarpedia.org/article/Frontal_eye_field"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
